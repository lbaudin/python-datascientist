<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lino Galiana">
<meta name="dcterms.date" content="2020-10-29">
<meta name="description" content="Ce chapitre continue de présenter l’approche de nettoyage de données du NLP en s’appuyant sur le corpus de trois auteurs anglo-saxons : Mary Shelley, Edgar Allan Poe, H.P. Lovecraft. Dans cette série d’exercice nous mettons en oeuvre de manière plus approfondie les différentes méthodes présentées précédemment.">

<title>Python pour la data science - Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../content/NLP/03_lda.html" rel="next">
<link href="../../content/NLP/01_intro.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background: #e9f3fa;
      }
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta name="twitter:title" content="Python pour la data science - Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words">
<meta name="twitter:description" content="Ce chapitre continue de présenter l’approche de nettoyage de données
du NLP en s’appuyant sur le corpus de trois auteurs
anglo-saxons : Mary Shelley, Edgar Allan Poe, H.P. Lovecraft.
Dans cette série d’exercice nous mettons en oeuvre de manière
plus approfondie les différentes méthodes présentées
précédemment.">
<meta name="twitter:image" content="https://pythonds.linogaliana.fr/content/NLP/featured_nlp_exo.png">
<meta name="twitter:image-height" content="480">
<meta name="twitter:image-width" content="672">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="Python pour la data science">
<meta name="citation_author" content="Lino Galiana">
<meta name="citation_publication_date" content="2023">
<meta name="citation_cover_date" content="2023">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2020-10-29">
<meta name="citation_fulltext_html_url" content="https://pythonds.linogaliana.fr/">
<meta name="citation_doi" content="10.5281/zenodo.8229676">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Coding for economists;,citation_author=undefined Turrell;,citation_author=undefined contributors;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://aeturrell.github.io/coding-for-economists;">
<meta name="citation_reference" content="citation_title=R for data science;,citation_author=Hadley Wickham;,citation_author=Mine Çetinkaya-Rundel;,citation_author=Garrett Grolemund;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;">
<meta name="citation_reference" content="citation_title=Computational reproducibility of jupyter notebooks from biomedical publications;,citation_author=Sheeba Samuel;,citation_author=Daniel Mietchen;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2308.07333;">
<meta name="citation_reference" content="citation_title=Python data science handbook: Essential tools for working with data;,citation_author=Jake VanderPlas;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Machine learning methods that economists should know about;,citation_author=Susan Athey;,citation_author=Guido W Imbens;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=11;,citation_journal_title=Annual Review of Economics;,citation_publisher=Annual Reviews;">
<meta name="citation_reference" content="citation_title=Fuzzy matching on big-data an illustration with scanner data and crowd-sourced nutritional data;,citation_author=Lino Galiana;,citation_author=Milena Suarez Castillo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_publisher=Proceedings of the 2022 &amp;amp;amp;quot;Journées de Méthodologie Statistiques&amp;quot;;">
<meta name="citation_reference" content="citation_title=Data visualization with python and JavaScript;,citation_author=Kyran Dale;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Sémiologie graphique;,citation_author=Jacques Bertin;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;">
<meta name="citation_reference" content="citation_title=La sémiologie graphique de jacques bertin a cinquante ans;,citation_author=Gilles Palsky;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Visions carto (en ligne);">
<meta name="citation_reference" content="citation_title=Fundamentals of data visualization: A primer on making informative and compelling figures;,citation_author=Claus O Wilke;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=How to train BERT with an academic budget;,citation_author=Peter Izsak;,citation_author=Moshe Berchansky;,citation_author=Omer Levy;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2104.07705;">
<meta name="citation_reference" content="citation_title=Python for data analysis: Data wrangling with pandas, NumPy, and IPython;,citation_author=Wes McKinney;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Residential segregation, daytime segregation and spatial frictions: An analysis from mobile phone data;,citation_author=Lino Galiana;,citation_author=François Sémécurbe;,citation_author=Benjamin Sakarovitch;,citation_author=Zbigniew Smoreda;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_publisher=Insee Working Paper;">
<meta name="citation_reference" content="citation_title=Fuzzy matching on big-data: An illustration with scanner and crowd-sourced nutritional datasets;,citation_abstract=Food retailers’ scanner data provide unprecedented details on local consumption, provided that product identifiers allow a linkage with features of interest, such as nutritional information. In this paper, we enrich a large retailer dataset with nutritional information extracted from crowd-sourced and administrative nutritional datasets. To compensate for imperfect matching through the barcode, we develop a methodology to efficiently match short textual descriptions. After a preprocessing step to normalize short labels, we resort to fuzzy matching based on several tokenizers (including n-grams) by querying an ElasticSearch customized index and validate candidates echos as matches with a Levensthein edit-distance and an embedding-based similarity measure created from a siamese neural network model. The pipeline is composed of several steps successively relaxing constraints to find relevant matching candidates.;,citation_author=Lino Galiana;,citation_author=Milena Suarez Castillo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://doi.org/10.1145/3524458.3547244;,citation_doi=10.1145/3524458.3547244;,citation_isbn=9781450392846;,citation_conference_title=Proceedings of the 2022 ACM conference on information technology for social good;,citation_conference=Association for Computing Machinery;,citation_series_title=GoodIT ’22;">
<meta name="citation_reference" content="citation_title=Guide de sémiologie cartographique;,citation_author=undefined Insee;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_publisher=Insee Working Paper;">
<meta name="citation_reference" content="citation_title=Energy and policy considerations for deep learning in NLP;,citation_author=Emma Strubell;,citation_author=Ananya Ganesh;,citation_author=Andrew McCallum;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1906.02243;">
<meta name="citation_reference" content="citation_title=High-resolution image synthesis with latent diffusion models;,citation_author=Robin Rombach;,citation_author=Andreas Blattmann;,citation_author=Dominik Lorenz;,citation_author=Patrick Esser;,citation_author=Björn Ommer;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR);">
<meta name="citation_reference" content="citation_title=Apache arrow and the&amp;amp;amp;quot; 10 things i hate about pandas;,citation_author=Wes McKinney;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=21;,citation_journal_title=Blog, September;">
<meta name="citation_reference" content="citation_title=Many researchers were not compliant with their published data sharing statement: Mixed-methods study;,citation_author=Mirko Gabelica;,citation_author=Ružica Bojčić;,citation_author=Livia Puljak;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=Journal of Clinical Epidemiology;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Credit scoring in the era of big data;,citation_author=Mikella Hurley;,citation_author=Julius Adebayo;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=18;,citation_journal_title=Yale JL &amp;amp;amp; Tech.;,citation_publisher=HeinOnline;">
<meta name="citation_reference" content="citation_title=Econometrics and machine learning;,citation_author=Arthur Charpentier;,citation_author=Emmanuel Flachaire;,citation_author=Antoine Ly;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=505;,citation_journal_title=Economie et Statistique;,citation_publisher=Persée-Portail des revues scientifiques en SHS;">
<meta name="citation_reference" content="citation_title=Machine learning: An applied econometric approach;,citation_author=Sendhil Mullainathan;,citation_author=Jann Spiess;,citation_publication_date=2017-05;,citation_cover_date=2017-05;,citation_year=2017;,citation_fulltext_html_url=https://www.aeaweb.org/articles?id=10.1257/jep.31.2.87;,citation_issue=2;,citation_doi=10.1257/jep.31.2.87;,citation_volume=31;,citation_journal_title=Journal of Economic Perspectives;">
<meta name="citation_reference" content="citation_title=Le problème du réalisme des hypothèses en économie politique;,citation_author=Pierre Salmon;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=The methodology of positive economics;,citation_author=Milton Friedman;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;,citation_inbook_title=Essays in positive economics;">
<meta name="citation_reference" content="citation_title=L’empreinte carbone du numérique;,citation_author=undefined Arcep;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Leakage and the reproducibility crisis in ML-based science;,citation_author=Sayash Kapoor;,citation_author=Arvind Narayanan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2207.07048;,citation_doi=10.48550/ARXIV.2207.07048;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Data scientist, the sexiest job of the 21st century;,citation_author=Thomas H Davenport;,citation_author=DJ Patil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century;,citation_issue=5;,citation_volume=90;,citation_journal_title=Harvard business review;">
<meta name="citation_reference" content="citation_title=Is data scientist still the sexiest job of the 21st century?;,citation_author=Thomas H Davenport;,citation_author=DJ Patil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century;,citation_issue=5;,citation_volume=90;,citation_journal_title=Harvard business review;">
</head>

<body class="nav-sidebar floating nav-fixed">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Python pour la data science</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-introduction" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Introduction</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-introduction">    
        <li>
    <a class="dropdown-item" href="../../content/getting-started/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/01_installation.html" rel="" target="">
 <span class="dropdown-text">Configuration de Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/02_DS_environment.html" rel="" target="">
 <span class="dropdown-text">L’environnement Python pour la data science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/03_data_analysis.html" rel="" target="">
 <span class="dropdown-text">Comment aborder un jeu de données</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/04_python_practice.html" rel="" target="">
 <span class="dropdown-text">Bonne pratique de Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/05_rappels_types.html" rel="" target="">
 <span class="dropdown-text">Quelques rappels sur les principes de base de Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/06_rappels_fonctions.html" rel="" target="">
 <span class="dropdown-text">Modules, tests, boucles, fonctions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/07_rappels_classes.html" rel="" target="">
 <span class="dropdown-text">Les classes en Python</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-manipuler" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Manipuler</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-manipuler">    
        <li>
    <a class="dropdown-item" href="../../content/manipulation/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/01_numpy.html" rel="" target="">
 <span class="dropdown-text">Numpy, la brique de base de la data science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/02a_pandas_tutorial.html" rel="" target="">
 <span class="dropdown-text">Introduction à Pandas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/02b_pandas_TP.html" rel="" target="">
 <span class="dropdown-text">Pratique de pandas : un exemple complet</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/03_geopandas_tutorial.html" rel="" target="">
 <span class="dropdown-text">Données spatiales : découverte de geopandas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/03_geopandas_TP.html" rel="" target="">
 <span class="dropdown-text">Pratique de geopandas avec les données vélib</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/04a_webscraping_TP.html" rel="" target="">
 <span class="dropdown-text">Webscraping avec Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/04c_API_TP.html" rel="" target="">
 <span class="dropdown-text">Récupérer des données avec des API depuis Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/04b_regex_TP.html" rel="" target="">
 <span class="dropdown-text">Maîtriser les expressions régulières</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/07_dask.html" rel="" target="">
 <span class="dropdown-text">Introduction à dask grâce aux données DVF</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-communiquer" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Communiquer</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-communiquer">    
        <li>
    <a class="dropdown-item" href="../../content/visualisation/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/visualisation/matplotlib.html" rel="" target="">
 <span class="dropdown-text">De beaux graphiques avec python: mise en pratique</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/visualisation/maps.html" rel="" target="">
 <span class="dropdown-text">De belles cartes avec python: mise en pratique</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-modéliser" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Modéliser</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-modéliser">    
        <li>
    <a class="dropdown-item" href="../../content/modelisation/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/0_preprocessing.html" rel="" target="">
 <span class="dropdown-text">Préparation des données pour construire un modèle</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/1_modelevaluation.html" rel="" target="">
 <span class="dropdown-text">Evaluer la qualité d’un modèle</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/2_SVM.html" rel="" target="">
 <span class="dropdown-text">Classification: premier modèle avec les SVM</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/3_regression.html" rel="" target="">
 <span class="dropdown-text">Régression : une introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/4_featureselection.html" rel="" target="">
 <span class="dropdown-text">Sélection de variables : une introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/5_clustering.html" rel="" target="">
 <span class="dropdown-text">Clustering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/6_pipeline.html" rel="" target="">
 <span class="dropdown-text">Premier pas vers l’industrialisation avec les pipelines scikit</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-approfondissements" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Approfondissements</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-approfondissements">    
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/continuous_integration.html" rel="" target="">
 <span class="dropdown-text">Intégration continue avec Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/dallE.html" rel="" target="">
 <span class="dropdown-text">Génération d’images avec Python, DALL-E et StableDiffusion</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/s3.html" rel="" target="">
 <span class="dropdown-text">Les nouveaux modes d’accès aux données : le format parquet et les données sur le cloud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/elastic_approfondissement.html" rel="" target="">
 <span class="dropdown-text">Approfondissement ElasticSearch pour des recherches de proximité géographique</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/elastic_intro.html" rel="" target="">
 <span class="dropdown-text">Introduction à ElasticSearch pour la recherche textuelle</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-git" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Git</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-git">    
        <li>
    <a class="dropdown-item" href="../../content/git/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/git/introgit.html" rel="" target="">
 <span class="dropdown-text">Git : un élément essentiel au quotidien</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/git/exogit.html" rel="" target="">
 <span class="dropdown-text">Un cadavre exquis pour découvrir Git</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-annexes" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Annexes</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-annexes">    
        <li>
    <a class="dropdown-item" href="../../content/annexes/evaluation.html" rel="" target="">
 <span class="dropdown-text">Evaluation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/annexes/corrections.html" rel="" target="">
 <span class="dropdown-text">Corrections</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://linogaliana.github.io/python-datascientist-slides/#/title-slide" rel="" target="">
 <span class="dropdown-text">Slides de présentation</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://github.com/linogaliana/python-datascientist">
            Code source
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../content/NLP/02_exoclean.html">Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns">
                <div id="title-block-header-title" class="quarto-title page-columns page-full page-layout-full featured-image p-4" style="background-image: url(featured_nlp_exo.png);">
                <h1 class="title">Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</h1>
                                    <div class="quarto-categories">
                        <div class="quarto-category">NLP</div>
                        <div class="quarto-category">Exercice</div>
                      </div>
                          </div>
        
                <div>
          <div id="title-block-title-desc" class="description pt-4">
            <p>Ce chapitre continue de présenter l’approche de <strong>nettoyage de données</strong>
            du <code>NLP</code> en s’appuyant sur le corpus de trois auteurs
            anglo-saxons : Mary Shelley, Edgar Allan Poe, H.P. Lovecraft.
            Dans cette série d’exercice nous mettons en oeuvre de manière
            plus approfondie les différentes méthodes présentées
            précédemment.</p>
          </div>
        </div>
                
        
        <div class="quarto-title-meta">

            <div>
            <div class="quarto-title-meta-heading">Author</div>
            <div class="quarto-title-meta-contents">
                     <p>Lino Galiana </p>
                  </div>
          </div>
            
            <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">October 29, 2020</p>
            </div>
          </div>
          
            
          </div>
          
        
        
        

        </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quelques éléments pour comprendre les enjeux du NLP</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/02_exoclean.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/03_lda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Latent Dirichlet Allocation (LDA)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/04_word2vec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Méthodes de vectorisation : comptages et word embeddings</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/05_exo_supp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercices supplémentaires</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#librairies-nécessaires" id="toc-librairies-nécessaires" class="nav-link active" data-scroll-target="#librairies-nécessaires">Librairies nécessaires</a></li>
  <li><a href="#données-utilisées" id="toc-données-utilisées" class="nav-link" data-scroll-target="#données-utilisées">Données utilisées</a>
  <ul class="collapse">
  <li><a href="#fréquence-dun-mot" id="toc-fréquence-dun-mot" class="nav-link" data-scroll-target="#fréquence-dun-mot">Fréquence d’un mot</a></li>
  <li><a href="#premier-wordcloud" id="toc-premier-wordcloud" class="nav-link" data-scroll-target="#premier-wordcloud">Premier <em>wordcloud</em></a></li>
  <li><a href="#aparté-la-loi-de-zipf" id="toc-aparté-la-loi-de-zipf" class="nav-link" data-scroll-target="#aparté-la-loi-de-zipf">Aparté: la loi de Zipf</a></li>
  </ul></li>
  <li><a href="#nettoyage-dun-texte" id="toc-nettoyage-dun-texte" class="nav-link" data-scroll-target="#nettoyage-dun-texte">Nettoyage d’un texte</a></li>
  <li><a href="#tf-idf-calcul-de-fréquence" id="toc-tf-idf-calcul-de-fréquence" class="nav-link" data-scroll-target="#tf-idf-calcul-de-fréquence">TF-IDF: calcul de fréquence</a></li>
  <li><a href="#approche-contextuelle-les-n-gramms" id="toc-approche-contextuelle-les-n-gramms" class="nav-link" data-scroll-target="#approche-contextuelle-les-n-gramms">Approche contextuelle: les <em>n-gramms</em></a></li>
  <li><a href="#références" id="toc-références" class="nav-link" data-scroll-target="#références">Références</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/linogaliana/python-datascientist/edit/master/content/NLP/02_exoclean.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/linogaliana/python-datascientist/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">

<!-- source: https://github.com/gadenbuie/garrickadenbuie-com/blob/main/_partials/title-block-link-buttons/title-block.html -->
<!-- source: https://raw.githubusercontent.com/spcanelon/silvia/32853dd0e70a71514b0922ee306f80ed5897f776/_partials/title-block-link-buttons/title-block.html -->
<!-- 
<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title"> 
-->
<!-- <header id="title-block-header" class="quarto-title-block default page-columns"> -->
<!-- <div class="quarto-title page-columns page-full featured-image p-4" style="background-image: url(featured.png), url(featured.jpg), url(../featured.jpg);"> -->
    

<div class="cell markdown">
<p class="badges">
<a href="https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/NLP/02_exoclean.ipynb" class="github"><i class="fab fa-github"></i></a>
<a href="https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/NLP/02_exoclean.ipynb" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter" alt="Download"></a>
<a href="https://nbviewer.jupyter.org/github/linogaliana/python-datascientist-notebooksblob/main/notebooks/NLP/02_exoclean.ipynb" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter" alt="nbviewer"></a>
<a href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&amp;onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&amp;init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&amp;init.personalInitArgs=%C2%ABNLP%2002_exoclean%C2%BB&amp;security.allowlist.enabled=false" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&amp;logoColor=orange" alt="Onyxia"></a>
<a href="https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=true&amp;onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&amp;init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&amp;init.personalInitArgs=%C2%ABNLP%2002_exoclean%C2%BB&amp;security.allowlist.enabled=false" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&amp;logoColor=blue" alt="Onyxia"></a><br>
<a href="https://mybinder.org/v2/gh/linogaliana/python-datascientist-notebooks/main?filepath={binder_path}" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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" alt="Binder"></a>
<a href="https://colab.research.google.com/github/linogaliana/python-datascientist-notebooks/blob/main/notebooks/NLP/02_exoclean.ipynb" target="_blank" rel="noopener"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
<a href="https://github.dev/linogaliana/python-datascientist-notebooks/notebooks/NLP/02_exoclean.ipynb" target="_blank" rel="noopener"><img src="https://img.shields.io/static/v1?logo=visualstudiocode&amp;label=&amp;message=Open%20in%20Visual%20Studio%20Code&amp;labelColor=2c2c32&amp;color=007acc&amp;logoColor=007acc" alt="githubdev"></a>
</p>
<p></p>
</div>
<p>Cette page approfondit certains aspects présentés dans la
<a href="#nlp">partie introductive</a>. Après avoir travaillé sur le
<em>Comte de Monte Cristo</em>, on va continuer notre exploration de la littérature
avec cette fois des auteurs anglophones :</p>
<ul>
<li>Edgar Allan Poe, (EAP) ;</li>
<li>HP Lovecraft (HPL) ;</li>
<li>Mary Wollstonecraft Shelley (MWS).</li>
</ul>
<p>Les données sont disponibles ici : <a href="https://github.com/GU4243-ADS/spring2018-project1-ginnyqg/blob/master/data/spooky.csv">spooky.csv</a> et peuvent être requétées via l’url
<a href="https://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv" class="uri">https://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv</a>.</p>
<p>Le but va être dans un premier temps de regarder dans le détail les termes les plus fréquemment utilisés par les auteurs, de les représenter graphiquement.
On prendra appui sur l’approche <em>bag of words</em> présentée dans le chapitre précédent<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>Ce notebook est librement inspiré de :</p>
<ul>
<li>https://www.kaggle.com/enerrio/scary-nlp-with-spacy-and-keras</li>
<li>https://github.com/GU4243-ADS/spring2018-project1-ginnyqg</li>
<li>https://www.kaggle.com/meiyizi/spooky-nlp-and-topic-modelling-tutorial/notebook</li>
</ul>
<p>Les chapitres suivants permettront d’introduire aux enjeux de modélisation
de corpus textuels. Dans un premier temps, le modèle <code>LDA</code> permettra d’explorer
le principe des modèles bayésiens à couche cachées pour modéliser les sujets (<em>topics</em>)
présents dans un corpus et segmenter ces <em>topics</em> selon les mots qui les composent.</p>
<p>Le dernier chapitre de la partie visera à
prédire quel texte correspond à quel auteur à partir d’un modèle <code>Word2Vec</code>.
Cela sera un pas supplémentaire dans la formalisation puisqu’il s’agira de
représenter chaque mot d’un texte sous forme d’un vecteur de grande dimension, ce
qui nous permettra de rapprocher les mots entre eux dans un espace complexe.
Cette technique, dite des plongements de mots (<em>Word Embedding</em>),
permet ainsi de transformer une information complexe difficilement quantifiable
comme un mot
en un objet numérique qui peut ainsi être rapproché d’autres par des méthodes
algébriques. Pour découvrir ce concept, ce <a href="https://ssphub.netlify.app/post/word-embedding/">post de blog</a>
est particulièrement utile. En pratique, la technique des
plongements de mots permet d’obtenir des tableaux comme celui-ci:</p>
<div id="fig-relevanc-table-embedding" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="word_embedding.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="word_embedding.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
<figcaption class="figure-caption">Figure&nbsp;1: Illustration de l’intérêt des <em>embeddings</em> <span class="citation" data-cites="galianafuzzy">(<a href="#ref-galianafuzzy" role="doc-biblioref">Galiana and Castillo 2022</a>)</span></figcaption>
</figure>
</div>
<section id="librairies-nécessaires" class="level2">
<h2 class="anchored" data-anchor-id="librairies-nécessaires">Librairies nécessaires</h2>
<p>Cette page évoquera les principales librairies pour faire du NLP, notamment :</p>
<ul>
<li><a href="https://github.com/amueller/word_cloud">WordCloud</a></li>
<li><a href="https://www.nltk.org/">nltk</a></li>
<li><a href="https://spacy.io/">SpaCy</a></li>
<li><a href="https://keras.io/">Keras</a></li>
<li><a href="https://www.tensorflow.org/">TensorFlow</a></li>
</ul>
<p>Il faudra également installer les librairies <code>gensim</code> et <code>pywaffle</code></p>
<div class="cell markdown">
<div class="alert alert-warning" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-lightbulb"></i> Hint</h3>
<p>Comme dans la <a href="#nlp">partie précédente</a>, il faut télécharger quelques éléments pour que <code>NTLK</code> puisse fonctionner correctement. Pour cela, faire :</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'genesis'</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'omw-1.4'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>La liste des modules à importer est assez longue, la voici :</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> base64</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install pywaffle</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pywaffle <span class="im">import</span> Waffle</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer, CountVectorizer</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> NMF, LatentDirichletAllocation</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'genesis'</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'omw-1.4'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package stopwords to /github/home/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to /github/home/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package genesis to /github/home/nltk_data...
[nltk_data]   Unzipping corpora/genesis.zip.
[nltk_data] Downloading package wordnet to /github/home/nltk_data...
[nltk_data] Downloading package omw-1.4 to /github/home/nltk_data...</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>True</code></pre>
</div>
</div>
</section>
<section id="données-utilisées" class="level2">
<h2 class="anchored" data-anchor-id="données-utilisées">Données utilisées</h2>
<div class="cell markdown">
<div class="alert alert-success" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 1 : Importer les données spooky</h3>
<p><em>Pour ceux qui ont envie de tester leurs connaissances en pandas</em></p>
<ol type="1">
<li>Importer le jeu de données <code>spooky</code> à partir de l’URL <a href="https://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv" class="uri">https://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv</a> sous le nom <code>train</code>. L’encoding est <code>latin-1</code></li>
<li>Mettre des majuscules au nom des colonnes.</li>
<li>Retirer le prefix <code>id</code> de la colonne <code>Id</code> et appeler la nouvelle colonne <code>ID</code>.</li>
<li>Mettre l’ancienne colonne <code>Id</code> en index.</li>
</ol>
</div>
</div>
<p>Si vous ne faites pas l’exercice 1, pensez à charger les données en executant la fonction <code>get_data.py</code> :</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/NLP/get_data.py'</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(url, allow_redirects<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">open</span>(<span class="st">'getdata.py'</span>, <span class="st">'wb'</span>).write(r.content)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> getdata</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> getdata.create_train_dataframes()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ce code introduit une base nommée <code>train</code> dans l’environnement.</p>
<p>Le jeu de données met ainsi en regard un auteur avec une phrase qu’il a écrite :</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>train.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Text</th>
<th data-quarto-table-cell-role="th">Author</th>
<th data-quarto-table-cell-role="th">ID</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Id</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">id26305</td>
<td>This process, however, afforded me no means of...</td>
<td>EAP</td>
<td>26305</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">id17569</td>
<td>It never once occurred to me that the fumbling...</td>
<td>HPL</td>
<td>17569</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">id11008</td>
<td>In his left hand was a gold snuff box, from wh...</td>
<td>EAP</td>
<td>11008</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">id27763</td>
<td>How lovely is spring As we looked from Windsor...</td>
<td>MWS</td>
<td>27763</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">id12958</td>
<td>Finding nothing else, not even gold, the Super...</td>
<td>HPL</td>
<td>12958</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>On peut se rendre compte que les extraits des 3 auteurs ne sont
pas forcément équilibrés dans le jeu de données.
Il faudra en tenir compte dans la prédiction.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.barplot(x<span class="op">=</span>[<span class="st">'Edgar Allen Poe'</span>, <span class="st">'Mary W. Shelley'</span>, <span class="st">'H.P. Lovecraft'</span>], y<span class="op">=</span>train[<span class="st">'Author'</span>].value_counts())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/mamba/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning:

is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead

/opt/mamba/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning:

is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead

/opt/mamba/lib/python3.9/site-packages/seaborn/_oldcore.py:1765: FutureWarning:

unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.

/opt/mamba/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning:

is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/cell-12-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="02_exoclean_files/figure-html/cell-12-output-2.png" width="602" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div class="cell markdown">
<div class="alert alert-info" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-comment"></i> Note</h3>
<p>L’approche <em>bag of words</em> est présentée de
manière plus extensive dans le <a href="#nlp">chapitre précédent</a>.</p>
<p>L’idée est d’étudier la fréquence des mots d’un document et la
surreprésentation des mots par rapport à un document de
référence (appelé <em>corpus</em>).</p>
<p>Cette approche un peu simpliste mais très
efficace : on peut calculer des scores permettant par exemple de faire
de classification automatique de document par thème, de comparer la
similarité de deux documents. Elle est souvent utilisée en première analyse,
et elle reste la référence pour l’analyse de textes mal
structurés (tweets, dialogue tchat, etc.).</p>
<p>Les analyses tf-idf (<em>term frequency-inverse document frequency</em>) ou les
constructions d’indices de similarité cosinus reposent sur ce type d’approche.</p>
</div>
</div>
<section id="fréquence-dun-mot" class="level3">
<h3 class="anchored" data-anchor-id="fréquence-dun-mot">Fréquence d’un mot</h3>
<p>Avant de s’adonner à une analyse systématique du champ lexical de chaque
auteur, on se focaliser dans un premier temps sur un unique mot, le mot <em>fear</em>.</p>
<div class="cell markdown">
<div class="alert alert-comment" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-comment"></i> Note</h3>
<p>L’exercice ci-dessous présente une représentation graphique nommée
<em>waffle chart</em>. Il s’agit d’une approche préférable aux
camemberts qui sont des graphiques manipulables car l’oeil humain se laisse
facilement berner par cette représentation graphique qui ne respecte pas
les proportions.</p>
</div>
</div>
<div class="cell markdown">
<div class="alert alert-success" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 2 : Fréquence d'un mot</h3>
<ol type="1">
<li>Compter le nombre de phrases, pour chaque auteur, où apparaît le mot <code>fear</code>.</li>
<li>Utiliser <code>pywaffle</code> pour obtenir les graphiques ci-dessous qui résument
de manière synthétique le nombre d’occurrences du mot <em>“fear”</em> par auteur.</li>
<li>Refaire l’analyse avec le mot <em>“horror”</em>.</li>
</ol>
</div>
</div>
<p>A l’issue de la question 1, vous devriez obtenir le tableau
de fréquence suivant:</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Text</th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">wordtoplot</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Author</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">EAP</td>
<td>This process, however, afforded me no means of...</td>
<td>2630511008096741351519322166071718908441148621...</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">HPL</td>
<td>It never once occurred to me that the fumbling...</td>
<td>1756912958197641888620836080752790708121117330...</td>
<td>160</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MWS</td>
<td>How lovely is spring As we looked from Windsor...</td>
<td>2776322965009121673712799131170076400683052582...</td>
<td>211</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Ceci permet d’obtenir le <em>waffle chart</em> suivant:</p>
<div class="cell" data-execution_count="15">
<div class="cell-output cell-output-display" data-execution_count="15">
<div id="fig-waffle-fear" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/fig-waffle-fear-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Répartition du terme fear dans le corpus de nos trois auteurs"><img src="02_exoclean_files/figure-html/fig-waffle-fear-output-1.png" width="662" height="359" class="figure-img"></a></p>
<figcaption class="figure-caption">Figure&nbsp;2: Répartition du terme fear dans le corpus de nos trois auteurs</figcaption>
</figure>
</div>
</div>
</div>
<p>On remarque ainsi de manière très intuitive
le déséquilibre de notre jeu de données
lorsqu’on se focalise sur le terme <em>“peur”</em>
où Mary Shelley représente près de 50%
des observations.</p>
<p>Si on reproduit cette analyse avec le terme <em>“horror”</em>, on peut
en conclure que la peur est plus évoquée par Mary Shelley
(sentiment assez naturel face à la créature du docteur Frankenstein) alors
que Lovecraft n’a pas volé sa réputation d’écrivain de l’horreur !</p>
<div class="cell" data-execution_count="18">
<div class="cell-output cell-output-display" data-execution_count="18">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/cell-19-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="02_exoclean_files/figure-html/cell-19-output-1.png" width="450" height="470" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="premier-wordcloud" class="level3">
<h3 class="anchored" data-anchor-id="premier-wordcloud">Premier <em>wordcloud</em></h3>
<p>Pour aller plus loin dans l’analyse du champ lexical de chaque auteur,
on peut représenter un <code>wordcloud</code> qui permet d’afficher chaque mot avec une
taille proportionnelle au nombre d’occurrence de celui-ci.</p>
<div class="cell markdown">
<div class="alert alert-success" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 3 : Wordcloud</h3>
<ol type="1">
<li>En utilisant la fonction <code>wordCloud</code>, faire trois nuages de mot pour représenter les mots les plus utilisés par chaque auteur.</li>
<li>Calculer les 25 mots plus communs pour chaque auteur et représenter les trois histogrammes des décomptes.</li>
</ol>
</div>
</div>
<p>Le <em>wordcloud</em> pour nos différents auteurs est le suivant:</p>
<div class="cell" data-execution_count="20">
<div class="cell-output cell-output-display" data-execution_count="20">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/cell-21-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="02_exoclean_files/figure-html/cell-21-output-1.png" width="1135" height="820" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Enfin, si on fait un histogramme des fréquences,
cela donnera :</p>
<div class="cell" data-execution_count="22">
<div class="cell-output cell-output-display" data-execution_count="22">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/cell-23-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="02_exoclean_files/figure-html/cell-23-output-1.png" width="278" height="851" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>On voit ici que ce sont des mots communs, comme <em>“the”</em>, <em>“of”</em>, etc. sont très
présents. Mais ils sont peu porteurs d’information, on peut donc les éliminer
avant de faire une analyse syntaxique poussée.
Ceci est une démonstration par l’exemple qu’il vaut mieux nettoyer le texte avant de
l’analyser (sauf si on est intéressé
par la loi de Zipf, cf.&nbsp;exercice suivant).</p>
</section>
<section id="aparté-la-loi-de-zipf" class="level3">
<h3 class="anchored" data-anchor-id="aparté-la-loi-de-zipf">Aparté: la loi de Zipf</h3>
<div class="cell markdown">
<div class="alert alert-warning" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> La loi de Zipf</h3>
<p>Dans son sens strict, la loi de Zipf prévoit que
dans un texte donné, la fréquence d’occurrence <span class="math inline">\(f(n_i)\)</span> d’un mot est
liée à son rang <span class="math inline">\(n_i\)</span> dans l’ordre des fréquences par une loi de la forme
<span class="math inline">\(f(n_i) = c/n_i\)</span> où <span class="math inline">\(c\)</span> est une constante. Zipf, dans les années 1930, se basait sur l’oeuvre
de Joyce, <em>Ulysse</em> pour cette affirmation.</p>
<p>Plus généralement, on peut dériver la loi de Zipf d’une distribution exponentielle des fréquences : <span class="math inline">\(f(n_i) = cn_{i}^{-k}\)</span>. Cela permet d’utiliser la famille des modèles linéaires généralisés, notamment les régressions poissonniennes, pour mesurer les paramètres de la loi. Les modèles linéaire traditionnels en <code>log</code> souffrent en effet, dans ce contexte, de biais (la loi de Zipf est un cas particulier d’un modèle gravitaire, où appliquer des OLS est une mauvaise idée, cf.&nbsp;<a href="https://linogaliana.netlify.app/publication/2020-segregation/"><span class="citation" data-cites="galiana2020segregation">Galiana et al. (<span>2020</span>)</span></a> pour les limites).</p>
</div>
</div>
<p>Un modèle exponentiel peut se représenter par un modèle de Poisson ou, si
les données sont très dispersées, par un modèle binomial négatif. Pour
plus d’informations, consulter l’annexe de <span class="citation" data-cites="galiana2020segregation">Galiana et al. (<a href="#ref-galiana2020segregation" role="doc-biblioref">2020</a>)</span>.
La technique économétrique associée pour l’estimation est
les modèles linéaires généralisés (GLM) qu’on peut
utiliser en <code>Python</code> via le
package <code>statsmodels</code><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<p><span class="math display">\[
\mathbb{E}\bigg( f(n_i)|n_i \bigg) = \exp(\beta_0 + \beta_1 \log(n_i))
\]</span></p>
<p>Prenons les résultats de l’exercice précédent et enrichissons les du rang et de la fréquence d’occurrence d’un mot :</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>count_words <span class="op">=</span> pd.DataFrame({<span class="st">'counter'</span> : train</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'Author'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> s: <span class="st">' '</span>.join(s[<span class="st">'Text'</span>]).split())</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> s: Counter(s))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> s: s.most_common())</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    .explode()}</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>count_words[[<span class="st">'word'</span>,<span class="st">'count'</span>]] <span class="op">=</span> pd.DataFrame(count_words[<span class="st">'counter'</span>].tolist(), index<span class="op">=</span>count_words.index)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>count_words <span class="op">=</span> count_words.reset_index()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>count_words <span class="op">=</span> count_words.assign(</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    tot_mots_auteur <span class="op">=</span> <span class="kw">lambda</span> x: (x.groupby(<span class="st">"Author"</span>)[<span class="st">'count'</span>].transform(<span class="st">'sum'</span>)),</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    freq <span class="op">=</span> <span class="kw">lambda</span> x: x[<span class="st">'count'</span>] <span class="op">/</span>  x[<span class="st">'tot_mots_auteur'</span>],</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    rank <span class="op">=</span> <span class="kw">lambda</span> x: x.groupby(<span class="st">"Author"</span>)[<span class="st">'count'</span>].transform(<span class="st">'rank'</span>, ascending <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Commençons par représenter la relation entre la fréquence et le rang:</p>
<p>Nous avons bien, graphiquement, une relation log-linéaire entre les deux:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>g.figure.get_figure()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/cell-26-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="02_exoclean_files/figure-html/cell-26-output-1.png" width="547" height="471" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Avec <code>statsmodels</code>, vérifions plus formellement cette relation:</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>exog <span class="op">=</span> sm.add_constant(np.log(count_words[<span class="st">'rank'</span>].astype(<span class="bu">float</span>)))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.GLM(count_words[<span class="st">'freq'</span>].astype(<span class="bu">float</span>), exog, family <span class="op">=</span> sm.families.Poisson()).fit()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Afficher les résultats du modèle</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                   freq   No. Observations:                69301
Model:                            GLM   Df Residuals:                    69299
Model Family:                 Poisson   Df Model:                            1
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -23.011
Date:                Sun, 05 Nov 2023   Deviance:                     0.065676
Time:                        10:11:07   Pearson chi2:                   0.0656
No. Iterations:                     5   Pseudo R-squ. (CS):          0.0002431
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -2.4388      1.089     -2.239      0.025      -4.574      -0.303
rank          -0.9831      0.189     -5.196      0.000      -1.354      -0.612
==============================================================================</code></pre>
</div>
</div>
<p>Le coefficient de la régression est presque 1 ce qui suggère bien une relation
quasiment log-linéaire entre le rang et la fréquence d’occurrence d’un mot.
Dit autrement, le mot le plus utilisé l’est deux fois plus que le deuxième
mois le plus fréquent qui l’est trois plus que le troisième, etc.</p>
</section>
</section>
<section id="nettoyage-dun-texte" class="level2">
<h2 class="anchored" data-anchor-id="nettoyage-dun-texte">Nettoyage d’un texte</h2>
<p>Les premières étapes dans le nettoyage d’un texte, qu’on a
développé au cours du <a href="#nlp">chapitre précédent</a>, sont :</p>
<ul>
<li>suppression de la ponctuation</li>
<li>suppression des <em>stopwords</em></li>
</ul>
<p>Cela passe par la tokenisation d’un texte, c’est-à-dire la décomposition
de celui-ci en unités lexicales (les <em>tokens</em>).
Ces unités lexicales peuvent être de différentes natures,
selon l’analyse que l’on désire mener.
Ici, on va définir les tokens comme étant les mots utilisés.</p>
<p>Plutôt que de faire soi-même ce travail de nettoyage,
avec des fonctions mal optimisées,
on peut utiliser la librairie <code>nltk</code> comme détaillé <a href="#nlp">précédemment</a>.</p>
<div class="cell markdown">
<div class="alert alert-success" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 4 : Nettoyage du texte</h3>
<p>Repartir de <code>train</code>, notre jeu de données d’entraînement. Pour rappel, <code>train</code> a la structure suivante :</p>
<ol type="1">
<li>Tokeniser chaque phrase avec <code>nltk</code>.</li>
<li>Retirer les stopwords avec <code>nltk</code>.</li>
</ol>
</div>
</div>
<p>Pour rappel, au début de l’exercice, le <code>DataFrame</code> présente l’aspect suivant:</p>
<div class="cell" data-execution_count="27">
<div class="cell-output cell-output-display" data-execution_count="27">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Text</th>
<th data-quarto-table-cell-role="th">Author</th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">wordtoplot</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Id</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">id26305</td>
<td>This process, however, afforded me no means of...</td>
<td>EAP</td>
<td>26305</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">id17569</td>
<td>It never once occurred to me that the fumbling...</td>
<td>HPL</td>
<td>17569</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Après tokenisation, il devrait avoir cet aspect :</p>
<div class="cell" data-execution_count="28">
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>ID     Author
00001  MWS       [Idris, was, well, content, with, this, resolv...
00002  HPL       [I, was, faint, even, fainter, than, the, hate...
dtype: object</code></pre>
</div>
</div>
<p>Après le retrait des stopwords, cela donnera:</p>
<div class="cell markdown">
<div class="alert alert-warning" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-lightbulb"></i> Hint</h3>
<p>La méthode <code>apply</code> est très pratique ici car nous avons une phrase par ligne. Plutôt que de faire un <code>DataFrame</code> par auteur, ce qui n’est pas une approche très flexible, on peut directement appliquer la tokenisation
sur notre <code>DataFrame</code> grâce à <code>apply</code>, sans le diviser.</p>
</div>
</div>
<p>Ce petit nettoyage permet d’arriver à un texte plus intéressant en termes d’analyse lexicale. Par exemple, si on reproduit l’analyse précédente… :</p>
<div class="cell" data-execution_count="31">
<div class="cell-output cell-output-display" data-execution_count="31">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="02_exoclean_files/figure-html/cell-32-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="02_exoclean_files/figure-html/cell-32-output-1.png" width="1135" height="820" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Pour aller plus loin dans l’harmonisation d’un texte, il est possible de
mettre en place les classes d’équivalence développées dans la
<a href="#nlp">partie précédente</a> afin de remplacer différentes variations d’un même
mot par une forme canonique :</p>
<ul>
<li><p>la <strong>racinisation</strong> (<em>stemming</em>) assez fruste mais rapide, notamment
en présence de fautes d’orthographe. Dans ce cas, <em>chevaux</em> peut devenir <em>chev</em>
mais être ainsi confondu avec <em>chevet</em> ou <em>cheveux</em>.
Cette méthode est généralement plus simple à mettre en oeuvre, quoique
plus fruste.</p></li>
<li><p>la <strong>lemmatisation</strong> qui requiert la connaissance des statuts
grammaticaux (exemple : <em>chevaux</em> devient <em>cheval</em>).
Elle est mise en oeuvre, comme toujours avec <code>nltk</code>, à travers un
modèle. En l’occurrence, un <code>WordNetLemmatizer</code> (WordNet est une base
lexicographique ouverte). Par exemple, les mots <em>“women”</em>, <em>“daughters”</em>
et <em>“leaves”</em> seront ainsi lemmatisés de la manière suivante :</p></li>
</ul>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>lemm <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> word <span class="kw">in</span> [<span class="st">"women"</span>,<span class="st">"daughters"</span>, <span class="st">"leaves"</span>]:</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"The lemmatized form of </span><span class="sc">%s</span><span class="st"> is: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(lemm.lemmatize(word)) <span class="op">%</span> word)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The lemmatized form of women is: woman
The lemmatized form of daughters is: daughter
The lemmatized form of leaves is: leaf</code></pre>
</div>
</div>
<div class="cell markdown">
<div class="alert alert-info" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-comment"></i> Note</h3>
<p>Pour disposer du corpus nécessaire à la lemmatisation, il faut, la première fois,
télécharger celui-ci grâce aux commandes suivantes :</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'omw-1.4'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>On va se restreindre au corpus d’Edgar Allan Poe et repartir de la base de données
brute:</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>eap_clean <span class="op">=</span> train[train[<span class="st">"Author"</span>] <span class="op">==</span> <span class="st">"EAP"</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>eap_clean <span class="op">=</span> <span class="st">' '</span>.join(eap_clean[<span class="st">'Text'</span>])</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Tokenisation naïve sur les espaces entre les mots =&gt; on obtient une liste de mots</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">#tokens = eap_clean.split()</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>word_list <span class="op">=</span> nltk.word_tokenize(eap_clean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell markdown">
<div class="alert alert-warning" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 5 : Lemmatisation avec nltk</h3>
<p>Utiliser un <code>WordNetLemmatizer</code> et observer le résultat.</p>
<p>Optionnel: Effectuer la même tâche avec <code>spaCy</code></p>
</div>
</div>
<p>Le <code>WordNetLemmatizer</code> donnera le résultat suivant:</p>
</section>
<section id="tf-idf-calcul-de-fréquence" class="level2">
<h2 class="anchored" data-anchor-id="tf-idf-calcul-de-fréquence">TF-IDF: calcul de fréquence</h2>
<p>Le calcul <a href="https://fr.wikipedia.org/wiki/TF-IDF">tf-idf</a> (term <em>frequency–inverse document frequency</em>)
permet de calculer un score de proximité entre un terme de recherche et un
document (c’est ce que font les moteurs de recherche).</p>
<ul>
<li>La partie <code>tf</code> calcule une fonction croissante de la fréquence du terme de recherche dans le document à l’étude ;</li>
<li>La partie <code>idf</code> calcule une fonction inversement proportionnelle à la fréquence du terme dans l’ensemble des documents (ou corpus).</li>
</ul>
<p>Le score total, obtenu en multipliant les deux composantes,
permet ainsi de donner un score d’autant plus élevé que le terme est surréprésenté dans un document
(par rapport à l’ensemble des documents).
Il existe plusieurs fonctions, qui pénalisent plus ou moins les documents longs,
ou qui sont plus ou moins <em>smooth</em>.</p>
<div class="cell markdown">
<div class="alert alert-success" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 6 : TF-IDF: calcul de fréquence</h3>
<ol type="1">
<li>Utiliser le vectoriseur TF-IdF de <code>scikit-learn</code> pour transformer notre corpus en une matrice <code>document x terms</code>. Au passage, utiliser l’option <code>stop_words</code> pour ne pas provoquer une inflation de la taille de la matrice. Nommer le modèle <code>tfidf</code> et le jeu entraîné <code>tfs</code>.</li>
<li>Après avoir construit la matrice de documents x terms avec le code suivant, rechercher les lignes où les termes ayant la structure <code>abandon</code> sont non-nuls.</li>
<li>Trouver les 50 extraits où le score TF-IDF est le plus élevé et l’auteur associé. Vous devriez obtenir le classement suivant:</li>
</ol>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> tfidf.get_feature_names_out()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>corpus_index <span class="op">=</span> [n <span class="cf">for</span> n <span class="kw">in</span> <span class="bu">list</span>(tfidf.vocabulary_.keys())]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(tfs.todense(), columns<span class="op">=</span>feature_names)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aaem</th>
<th data-quarto-table-cell-role="th">ab</th>
<th data-quarto-table-cell-role="th">aback</th>
<th data-quarto-table-cell-role="th">abaft</th>
<th data-quarto-table-cell-role="th">abandon</th>
<th data-quarto-table-cell-role="th">abandoned</th>
<th data-quarto-table-cell-role="th">abandoning</th>
<th data-quarto-table-cell-role="th">abandonment</th>
<th data-quarto-table-cell-role="th">abaout</th>
<th data-quarto-table-cell-role="th">abased</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">zodiacal</th>
<th data-quarto-table-cell-role="th">zoilus</th>
<th data-quarto-table-cell-role="th">zokkar</th>
<th data-quarto-table-cell-role="th">zone</th>
<th data-quarto-table-cell-role="th">zones</th>
<th data-quarto-table-cell-role="th">zopyrus</th>
<th data-quarto-table-cell-role="th">zorry</th>
<th data-quarto-table-cell-role="th">zubmizzion</th>
<th data-quarto-table-cell-role="th">zuro</th>
<th data-quarto-table-cell-role="th">á¼</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.253506</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>

<p>5 rows × 24937 columns</p>
</div>
</div>
</div>
<p>Les lignes où les termes de abandon sont non nuls
sont les suivantes :</p>
<div class="cell" data-execution_count="37">
<div class="cell-output cell-output-stdout">
<pre><code>Index([    4,   116,   215,   571,   839,  1042,  1052,  1069,  2247,  2317,
        2505,  3023,  3058,  3245,  3380,  3764,  3886,  4425,  5289,  5576,
        5694,  6812,  7500,  9013,  9021,  9077,  9560, 11229, 11395, 11451,
       11588, 11827, 11989, 11998, 12122, 12158, 12189, 13666, 15259, 16516,
       16524, 16759, 17547, 18019, 18072, 18126, 18204, 18251],
      dtype='int64')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aaem</th>
<th data-quarto-table-cell-role="th">ab</th>
<th data-quarto-table-cell-role="th">aback</th>
<th data-quarto-table-cell-role="th">abaft</th>
<th data-quarto-table-cell-role="th">abandon</th>
<th data-quarto-table-cell-role="th">abandoned</th>
<th data-quarto-table-cell-role="th">abandoning</th>
<th data-quarto-table-cell-role="th">abandonment</th>
<th data-quarto-table-cell-role="th">abaout</th>
<th data-quarto-table-cell-role="th">abased</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">zodiacal</th>
<th data-quarto-table-cell-role="th">zoilus</th>
<th data-quarto-table-cell-role="th">zokkar</th>
<th data-quarto-table-cell-role="th">zone</th>
<th data-quarto-table-cell-role="th">zones</th>
<th data-quarto-table-cell-role="th">zopyrus</th>
<th data-quarto-table-cell-role="th">zorry</th>
<th data-quarto-table-cell-role="th">zubmizzion</th>
<th data-quarto-table-cell-role="th">zuro</th>
<th data-quarto-table-cell-role="th">á¼</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.253506</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">116</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.339101</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">215</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.235817</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">571</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.143788</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">839</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.285886</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>

<p>5 rows × 24937 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>Author
MWS    22
HPL    15
EAP    13
Name: Text, dtype: int64</code></pre>
</div>
</div>
<p>Les 10 scores les plus élevés sont les suivants :</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train.iloc[list_fear[:<span class="dv">9</span>]][<span class="st">'Text'</span>].values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['We could not fear we did not.' '"And now I do not fear death.'
 'Be of heart and fear nothing.' 'I smiled, for what had I to fear?'
 'Indeed I had no fear on her account.'
 'I have not the slightest fear for the result.'
 'At length, in an abrupt manner she asked, "Where is he?" "O, fear not," she continued, "fear not that I should entertain hope Yet tell me, have you found him?'
 '"I fear you are right there," said the Prefect.'
 'I went down to open it with a light heart, for what had I now to fear?']</code></pre>
</div>
</div>
<p>On remarque que les scores les plus élévés sont soient des extraits courts où le mot apparait une seule fois, soit des extraits plus longs où le mot fear apparaît plusieurs fois.</p>
<div class="cell markdown">
<div class="alert alert-info" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-comment"></i> Note</h3>
<p>La matrice <code>document x terms</code> est un exemple typique de matrice <em>sparse</em> puisque, dans des corpus volumineux, une grande diversité de vocabulaire peut être trouvée.</p>
</div>
</div>
</section>
<section id="approche-contextuelle-les-n-gramms" class="level2">
<h2 class="anchored" data-anchor-id="approche-contextuelle-les-n-gramms">Approche contextuelle: les <em>n-gramms</em></h2>
<p>Pour être en mesure de mener cette analyse, il est nécessaire de télécharger un corpus supplémentaire :</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'genesis'</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>nltk.corpus.genesis.words(<span class="st">'english-web.txt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package genesis to /github/home/nltk_data...
[nltk_data]   Package genesis is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>['In', 'the', 'beginning', 'God', 'created', 'the', ...]</code></pre>
</div>
</div>
<p>Il s’agit maintenant de raffiner l’analyse.</p>
<p>On s’intéresse non seulement aux mots et à leur fréquence, mais aussi aux mots qui suivent. Cette approche est essentielle pour désambiguiser les homonymes. Elle permet aussi d’affiner les modèles “bag-of-words”. Le calcul de n-grams (bigrams pour les co-occurences de mots deux-à-deux, tri-grams pour les co-occurences trois-à-trois, etc.) constitue la méthode la plus simple pour tenir compte du contexte.</p>
<p><code>nltk</code> offre des methodes pour tenir compte du contexte : pour ce faire, nous calculons les n-grams, c’est-à-dire l’ensemble des co-occurrences successives de mots n-à-n.&nbsp;En général, on se contente de bi-grams, au mieux de tri-grams :</p>
<ul>
<li>les modèles de classification, analyse du sentiment, comparaison de documents, etc. qui comparent des n-grams avec n trop grands sont rapidement confrontés au problème de données sparse, cela réduit la capacité prédictive des modèles ;</li>
<li>les performances décroissent très rapidement en fonction de n, et les coûts de stockage des données augmentent rapidement (environ n fois plus élevé que la base de données initiale).</li>
</ul>
<p>On va, rapidement, regarder dans quel contexte apparaît le mot <code>fear</code> dans
l’oeuvre d’Edgar Allan Poe (EAP). Pour cela, on transforme d’abord
le corpus EAP en tokens `nltk :</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>eap_clean <span class="op">=</span> train[train[<span class="st">"Author"</span>] <span class="op">==</span> <span class="st">"EAP"</span>]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>eap_clean <span class="op">=</span> <span class="st">' '</span>.join(eap_clean[<span class="st">'Text'</span>])</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> eap_clean.split()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens[:<span class="dv">10</span>])</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> nltk.Text(tokens)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['This', 'process,', 'however,', 'afforded', 'me', 'no', 'means', 'of', 'ascertaining', 'the']
&lt;Text: This process, however, afforded me no means of...&gt;</code></pre>
</div>
</div>
<p>Vous aurez besoin des fonctions <code>BigramCollocationFinder.from_words</code> et <code>BigramAssocMeasures.likelihood_ratio</code> :</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.collocations <span class="im">import</span> BigramCollocationFinder</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.metrics <span class="im">import</span> BigramAssocMeasures</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell markdown">
<div class="alert alert-success" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-pencil"></i> Exercice 7  : n-grams et contexte du mot fear</h3>
<ol type="1">
<li>Utiliser la méthode <code>concordance</code> pour afficher le contexte dans lequel apparaît le terme <code>fear</code>.</li>
<li>Sélectionner et afficher les meilleures collocation, par exemple selon le critère du ratio de vraisemblance.</li>
</ol>
<p>Lorsque deux mots sont fortement associés, cela est parfois dû au fait qu’ils apparaissent rarement. Il est donc parfois nécessaire d’appliquer des filtres, par exemple ignorer les bigrammes qui apparaissent moins de 5 fois dans le corpus.</p>
<ol start="3" type="1">
<li><p>Refaire la question précédente en utilisant toujours un modèle <code>BigramCollocationFinder</code> suivi de la méthode <code>apply_freq_filter</code> pour ne conserver que les bigrammes présents au moins 5 fois. Puis, au lieu d’utiliser la méthode de maximum de vraisemblance, testez la méthode <code>nltk.collocations.BigramAssocMeasures().jaccard</code>.</p></li>
<li><p>Ne s’intéresser qu’aux <em>collocations</em> qui concernent le mot <em>fear</em></p></li>
</ol>
</div>
</div>
<p>Avec la méthode <code>concordance</code> (question 1),
la liste devrait ressembler à celle-ci:</p>
<div class="cell" data-execution_count="43">
<div class="cell-output cell-output-stdout">
<pre><code>Exemples d'occurences du terme 'fear' :
Displaying 13 of 13 matches:
d quick unequal spoken apparently in fear as well as in anger. What he said wa
hutters were close fastened, through fear of robbers, and so I knew that he co
to details. I even went so far as to fear that, as I occasioned much trouble, 
years of age, was heard to express a fear "that she should never see Marie aga
ich must be entirely remodelled, for fear of serious accident I mean the steel
 my arm, and I attended her home. 'I fear that I shall never see Marie again.'
clusion here is absurd. "I very much fear it is so," replied Monsieur Maillard
bt of ultimately seeing the Pole. "I fear you are right there," said the Prefe
er occurred before.' Indeed I had no fear on her account. For a moment there w
erhaps so," said I; "but, Legrand, I fear you are no artist. It is my firm int
 raps with a hammer. Be of heart and fear nothing. My daughter, Mademoiselle M
e splendor. I have not the slightest fear for the result. The face was so far 
arriers of iron that hemmed me in. I fear you have mesmerized" adding immediat

</code></pre>
</div>
</div>
<p>Même si on peut facilement voir le mot avant et après, cette liste est assez difficile à interpréter car elle recoupe beaucoup d’informations.</p>
<p>La <code>collocation</code> consiste à trouver les bi-grammes qui
apparaissent le plus fréquemment ensemble. Parmi toutes les paires de deux mots observées,
il s’agit de sélectionner, à partir d’un modèle statistique, les “meilleures”.
On obtient donc avec cette méthode (question 2):</p>
<p>Si on modélise les meilleures collocations:</p>
<p>Cette liste a un peu plus de sens,
on a des noms de personnages, de lieux mais aussi des termes fréquemment employés ensemble
(<em>Chess Player</em> par exemple).</p>
<p>En ce qui concerne les <em>collocations</em> du mot fear:</p>
<p>Si on mène la même analyse pour le terme <em>love</em>, on remarque que de manière logique, on retrouve bien des sujets généralement accolés au verbe :</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>collocations_word(<span class="st">"love"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[('love', 'me'), ('love', 'he'), ('will', 'love'), ('I', 'love'), ('love', ','), ('you', 'love'), ('the', 'love')]</code></pre>
</div>
</div>
</section>
<section id="références" class="level2">




</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Références</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-galianafuzzy" class="csl-entry" role="listitem">
Galiana, Lino, and Milena Suarez Castillo. 2022. <span>“Fuzzy Matching on Big-Data an Illustration with Scanner Data and Crowd-Sourced Nutritional Data.”</span>
</div>
<div id="ref-galiana2020segregation" class="csl-entry" role="listitem">
Galiana, Lino, François Sémécurbe, Benjamin Sakarovitch, and Zbigniew Smoreda. 2020. <span>“Residential Segregation, Daytime Segregation and Spatial Frictions: An Analysis from Mobile Phone Data.”</span>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>L’approche <em>bag of words</em> est déjà, si on la pousse à ses limites, très intéressante. Elle peut notamment
faciliter la mise en cohérence de différents corpus
par la méthode des appariements flous
(cf.&nbsp;<a href="https://epic-davinci-acb57b.netlify.app/#1"><span class="citation" data-cites="galianafuzzy">Galiana and Castillo (<span>2022</span>)</span></a>.
Le <a href="#elastic">chapitre sur ElasticSearch</a> présent dans cette partie du cours présente quelques
éléments de ce travail sur les données de l’<code>OpenFoodFacts</code><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>La littérature sur les modèles gravitaires, présentée dans <span class="citation" data-cites="galiana2020segregation">Galiana et al. (<a href="#ref-galiana2020segregation" role="doc-biblioref">2020</a>)</span>,
donne quelques arguments pour privilégier les modèles GLM à des modèles log-linéaires
estimés par moindres carrés ordinaires.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@book{galiana2023,
  author = {Galiana, Lino},
  title = {Python Pour La Data Science},
  date = {2023},
  url = {https://pythonds.linogaliana.fr/},
  doi = {10.5281/zenodo.8229676},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-galiana2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Galiana, Lino. 2023. <em>Python Pour La Data Science</em>. <a href="https://doi.org/10.5281/zenodo.8229676">https://doi.org/10.5281/zenodo.8229676</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="linogaliana/python-datascientist" data-repo-id="MDEwOlJlcG9zaXRvcnkyODAxNjE2Nzc=" data-category="General" data-category-id="DIC_kwDOELLtjc4B-5TX" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../content/NLP/01_intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Quelques éléments pour comprendre les enjeux du NLP</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../content/NLP/03_lda.html" class="pagination-link">
        <span class="nav-page-text">Latent Dirichlet Allocation (LDA)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Python pour la <em>data science</em>, Lino Galiana.<br>
Licence <i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i><br>
Code source disponible sur <a href="https://github.com/linogaliana/python-datascientist"><code>Github</code></a></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">Site construit avec <i class="fa-brands fa-python" aria-label="python"></i> et <a href="https://quarto.org/"><code>Quarto</code></a><br>
Inspiration pour la mise en forme du site <a href="https://www.andreashandel.com">ici</a><br>
<a href="https://github.com/linogaliana/python-datascientist">Code source disponible sur <i class="fa-brands fa-github" aria-label="github"></i> <code>GitHub</code></a></div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","loop":true,"closeEffect":"zoom","descPosition":"bottom","selector":".lightbox"});</script>



</body></html>