<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lino Galiana">
<meta name="dcterms.date" content="2023-07-15">
<meta name="description" content="Les corpus textuels étant des objets de très grande dimension où le ratio signal/bruit est faible, il est nécessaire de mettre en oeuvre une série d’étapes de nettoyage de texte. Ce chapitre va explorer quelques méthodes classiques de nettoyage en s’appuyant sur le Comte de Monte Cristo d’Alexandre Dumas.">

<title>Python pour la data science - Quelques éléments pour comprendre les enjeux du NLP</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../content/NLP/02_exoclean.html" rel="next">
<link href="../../content/NLP/index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background: #e9f3fa;
      }
</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta name="twitter:title" content="Python pour la data science - Quelques éléments pour comprendre les enjeux du NLP">
<meta name="twitter:description" content="Les corpus textuels étant des objets de très grande dimension
où le ratio signal/bruit est faible, il est nécessaire de mettre
en oeuvre une série d’étapes de nettoyage de texte. Ce chapitre va
explorer quelques méthodes classiques de nettoyage en s’appuyant
sur le Comte de Monte Cristo d’Alexandre Dumas.">
<meta name="twitter:image" content="https://pythonds.linogaliana.fr/content/NLP/wordcloud_openfood_clean.png">
<meta name="twitter:image-height" content="746">
<meta name="twitter:image-width" content="1182">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="Python pour la data science">
<meta name="citation_author" content="Lino Galiana">
<meta name="citation_publication_date" content="2023">
<meta name="citation_cover_date" content="2023">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-07-15">
<meta name="citation_fulltext_html_url" content="https://pythonds.linogaliana.fr/">
<meta name="citation_doi" content="10.5281/zenodo.8229676">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Coding for economists;,citation_author=undefined Turrell;,citation_author=undefined contributors;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://aeturrell.github.io/coding-for-economists;">
<meta name="citation_reference" content="citation_title=Random forests;,citation_author=Leo Breiman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=45;,citation_journal_title=Machine learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Bagging predictors;,citation_author=Leo Breiman;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=24;,citation_journal_title=Machine learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=R for data science;,citation_author=Hadley Wickham;,citation_author=Mine Çetinkaya-Rundel;,citation_author=Garrett Grolemund;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;">
<meta name="citation_reference" content="citation_title=Computational reproducibility of jupyter notebooks from biomedical publications;,citation_author=Sheeba Samuel;,citation_author=Daniel Mietchen;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2308.07333;">
<meta name="citation_reference" content="citation_title=Python data science handbook: Essential tools for working with data;,citation_author=Jake VanderPlas;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Machine learning methods that economists should know about;,citation_author=Susan Athey;,citation_author=Guido W Imbens;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=11;,citation_journal_title=Annual Review of Economics;,citation_publisher=Annual Reviews;">
<meta name="citation_reference" content="citation_title=Fuzzy matching on big-data an illustration with scanner data and crowd-sourced nutritional data;,citation_author=Lino Galiana;,citation_author=Milena Suarez Castillo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_publisher=Proceedings of the 2022 &amp;amp;amp;quot;Journées de Méthodologie Statistiques&amp;quot;;">
<meta name="citation_reference" content="citation_title=Data visualization with python and JavaScript;,citation_author=Kyran Dale;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Sémiologie graphique;,citation_author=Jacques Bertin;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;">
<meta name="citation_reference" content="citation_title=La sémiologie graphique de jacques bertin a cinquante ans;,citation_author=Gilles Palsky;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Visions carto (en ligne);">
<meta name="citation_reference" content="citation_title=Fundamentals of data visualization: A primer on making informative and compelling figures;,citation_author=Claus O Wilke;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=How to train BERT with an academic budget;,citation_author=Peter Izsak;,citation_author=Moshe Berchansky;,citation_author=Omer Levy;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2104.07705;">
<meta name="citation_reference" content="citation_title=Python for data analysis: Data wrangling with pandas, NumPy, and IPython;,citation_author=Wes McKinney;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Residential segregation, daytime segregation and spatial frictions: An analysis from mobile phone data;,citation_author=Lino Galiana;,citation_author=François Sémécurbe;,citation_author=Benjamin Sakarovitch;,citation_author=Zbigniew Smoreda;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_publisher=Insee Working Paper;">
<meta name="citation_reference" content="citation_title=Fuzzy matching on big-data: An illustration with scanner and crowd-sourced nutritional datasets;,citation_abstract=Food retailers’ scanner data provide unprecedented details on local consumption, provided that product identifiers allow a linkage with features of interest, such as nutritional information. In this paper, we enrich a large retailer dataset with nutritional information extracted from crowd-sourced and administrative nutritional datasets. To compensate for imperfect matching through the barcode, we develop a methodology to efficiently match short textual descriptions. After a preprocessing step to normalize short labels, we resort to fuzzy matching based on several tokenizers (including n-grams) by querying an ElasticSearch customized index and validate candidates echos as matches with a Levensthein edit-distance and an embedding-based similarity measure created from a siamese neural network model. The pipeline is composed of several steps successively relaxing constraints to find relevant matching candidates.;,citation_author=Lino Galiana;,citation_author=Milena Suarez Castillo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://doi.org/10.1145/3524458.3547244;,citation_doi=10.1145/3524458.3547244;,citation_isbn=9781450392846;,citation_conference_title=Proceedings of the 2022 ACM conference on information technology for social good;,citation_conference=Association for Computing Machinery;,citation_series_title=GoodIT ’22;">
<meta name="citation_reference" content="citation_title=Guide de sémiologie cartographique;,citation_author=undefined Insee;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_publisher=Insee Working Paper;">
<meta name="citation_reference" content="citation_title=Energy and policy considerations for deep learning in NLP;,citation_author=Emma Strubell;,citation_author=Ananya Ganesh;,citation_author=Andrew McCallum;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1906.02243;">
<meta name="citation_reference" content="citation_title=High-resolution image synthesis with latent diffusion models;,citation_author=Robin Rombach;,citation_author=Andreas Blattmann;,citation_author=Dominik Lorenz;,citation_author=Patrick Esser;,citation_author=Björn Ommer;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR);">
<meta name="citation_reference" content="citation_title=Apache arrow and the&amp;amp;amp;quot; 10 things i hate about pandas;,citation_author=Wes McKinney;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=21;,citation_journal_title=Blog, September;">
<meta name="citation_reference" content="citation_title=Many researchers were not compliant with their published data sharing statement: Mixed-methods study;,citation_author=Mirko Gabelica;,citation_author=Ružica Bojčić;,citation_author=Livia Puljak;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=Journal of Clinical Epidemiology;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Credit scoring in the era of big data;,citation_author=Mikella Hurley;,citation_author=Julius Adebayo;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=18;,citation_journal_title=Yale JL &amp;amp;amp; Tech.;,citation_publisher=HeinOnline;">
<meta name="citation_reference" content="citation_title=Econometrics and machine learning;,citation_author=Arthur Charpentier;,citation_author=Emmanuel Flachaire;,citation_author=Antoine Ly;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=505;,citation_journal_title=Economie et Statistique;,citation_publisher=Persée-Portail des revues scientifiques en SHS;">
<meta name="citation_reference" content="citation_title=Machine learning: An applied econometric approach;,citation_author=Sendhil Mullainathan;,citation_author=Jann Spiess;,citation_publication_date=2017-05;,citation_cover_date=2017-05;,citation_year=2017;,citation_fulltext_html_url=https://www.aeaweb.org/articles?id=10.1257/jep.31.2.87;,citation_issue=2;,citation_doi=10.1257/jep.31.2.87;,citation_volume=31;,citation_journal_title=Journal of Economic Perspectives;">
<meta name="citation_reference" content="citation_title=Le problème du réalisme des hypothèses en économie politique;,citation_author=Pierre Salmon;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=The methodology of positive economics;,citation_author=Milton Friedman;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;,citation_inbook_title=Essays in positive economics;">
<meta name="citation_reference" content="citation_title=L’empreinte carbone du numérique;,citation_author=undefined Arcep;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Leakage and the reproducibility crisis in ML-based science;,citation_author=Sayash Kapoor;,citation_author=Arvind Narayanan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2207.07048;,citation_doi=10.48550/ARXIV.2207.07048;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Data scientist, the sexiest job of the 21st century;,citation_author=Thomas H Davenport;,citation_author=DJ Patil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century;,citation_issue=5;,citation_volume=90;,citation_journal_title=Harvard business review;">
<meta name="citation_reference" content="citation_title=Is data scientist still the sexiest job of the 21st century?;,citation_author=Thomas H Davenport;,citation_author=DJ Patil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century;,citation_issue=5;,citation_volume=90;,citation_journal_title=Harvard business review;">
</head>

<body class="nav-sidebar floating nav-fixed">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Python pour la data science</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-introduction" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Introduction</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-introduction">    
        <li>
    <a class="dropdown-item" href="../../content/getting-started/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/01_installation.html" rel="" target="">
 <span class="dropdown-text">Configuration de Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/02_DS_environment.html" rel="" target="">
 <span class="dropdown-text">L’environnement Python pour la data science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/03_data_analysis.html" rel="" target="">
 <span class="dropdown-text">Comment aborder un jeu de données</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/04_python_practice.html" rel="" target="">
 <span class="dropdown-text">Bonne pratique de Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/05_rappels_types.html" rel="" target="">
 <span class="dropdown-text">Quelques rappels sur les principes de base de Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/06_rappels_fonctions.html" rel="" target="">
 <span class="dropdown-text">Modules, tests, boucles, fonctions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/getting-started/07_rappels_classes.html" rel="" target="">
 <span class="dropdown-text">Les classes en Python</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-manipuler" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Manipuler</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-manipuler">    
        <li>
    <a class="dropdown-item" href="../../content/manipulation/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/01_numpy.html" rel="" target="">
 <span class="dropdown-text">Numpy, la brique de base de la data science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/02a_pandas_tutorial.html" rel="" target="">
 <span class="dropdown-text">Introduction à Pandas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/02b_pandas_TP.html" rel="" target="">
 <span class="dropdown-text">Pratique de pandas : un exemple complet</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/03_geopandas_tutorial.html" rel="" target="">
 <span class="dropdown-text">Données spatiales : découverte de geopandas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/03_geopandas_TP.html" rel="" target="">
 <span class="dropdown-text">Pratique de geopandas avec les données vélib</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/04a_webscraping_TP.html" rel="" target="">
 <span class="dropdown-text">Web scraping avec Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/04c_API_TP.html" rel="" target="">
 <span class="dropdown-text">Récupérer des données avec des API depuis Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/04b_regex_TP.html" rel="" target="">
 <span class="dropdown-text">Maîtriser les expressions régulières</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/manipulation/07_dask.html" rel="" target="">
 <span class="dropdown-text">Introduction à dask grâce aux données DVF</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-communiquer" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Communiquer</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-communiquer">    
        <li>
    <a class="dropdown-item" href="../../content/visualisation/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/visualisation/matplotlib.html" rel="" target="">
 <span class="dropdown-text">De beaux graphiques avec python : mise en pratique</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/visualisation/maps.html" rel="" target="">
 <span class="dropdown-text">De belles cartes avec python : mise en pratique</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-modéliser" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Modéliser</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-modéliser">    
        <li>
    <a class="dropdown-item" href="../../content/modelisation/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/0_preprocessing.html" rel="" target="">
 <span class="dropdown-text">Préparation des données pour construire un modèle</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/1_modelevaluation.html" rel="" target="">
 <span class="dropdown-text">Evaluer la qualité d’un modèle</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/2_SVM.html" rel="" target="">
 <span class="dropdown-text">Classification: premier modèle avec les SVM</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/3_regression.html" rel="" target="">
 <span class="dropdown-text">Régression : une introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/4_featureselection.html" rel="" target="">
 <span class="dropdown-text">Sélection de variables : une introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/5_clustering.html" rel="" target="">
 <span class="dropdown-text">Clustering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modelisation/6_pipeline.html" rel="" target="">
 <span class="dropdown-text">Premier pas vers l’industrialisation avec les pipelines scikit</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-nlp" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">NLP</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-nlp">    
        <li>
    <a class="dropdown-item" href="../../content/NLP/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/NLP/01_intro.html" rel="" target="">
 <span class="dropdown-text">Quelques éléments pour comprendre les enjeux du NLP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/NLP/02_exoclean.html" rel="" target="">
 <span class="dropdown-text">Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/NLP/03_lda.html" rel="" target="">
 <span class="dropdown-text">Latent Dirichlet Allocation (LDA)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/NLP/04_word2vec.html" rel="" target="">
 <span class="dropdown-text">Méthodes de vectorisation : comptages et word embeddings</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/NLP/05_exo_supp.html" rel="" target="">
 <span class="dropdown-text">Exercices supplémentaires</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-approfondissements" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Approfondissements</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-approfondissements">    
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/continuous_integration.html" rel="" target="">
 <span class="dropdown-text">Intégration continue avec Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/dallE.html" rel="" target="">
 <span class="dropdown-text">Génération d’images avec Python, DALL-E et StableDiffusion</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/s3.html" rel="" target="">
 <span class="dropdown-text">Les nouveaux modes d’accès aux données : le format parquet et les données sur le cloud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/elastic_approfondissement.html" rel="" target="">
 <span class="dropdown-text">Approfondissement ElasticSearch pour des recherches de proximité géographique</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/modern-ds/elastic_intro.html" rel="" target="">
 <span class="dropdown-text">Introduction à ElasticSearch pour la recherche textuelle</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-git" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Git</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-git">    
        <li>
    <a class="dropdown-item" href="../../content/git/index.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/git/introgit.html" rel="" target="">
 <span class="dropdown-text">Git : un élément essentiel au quotidien</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/git/exogit.html" rel="" target="">
 <span class="dropdown-text">Un cadavre exquis pour découvrir Git</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-annexes" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Annexes</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-annexes">    
        <li>
    <a class="dropdown-item" href="../../content/annexes/evaluation.html" rel="" target="">
 <span class="dropdown-text">Evaluation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../content/annexes/corrections.html" rel="" target="">
 <span class="dropdown-text">Corrections</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://linogaliana.github.io/python-datascientist-slides/#/title-slide" rel="" target="">
 <span class="dropdown-text">Slides de présentation</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://github.com/linogaliana/python-datascientist">
            Code source
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../content/NLP/01_intro.html">Quelques éléments pour comprendre les enjeux du NLP</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns">
                <div id="title-block-header-title" class="quarto-title page-columns page-full page-layout-full featured-image p-4" style="background-image: url(wordcloud_openfood_clean.png);">
                <h1 class="title">Quelques éléments pour comprendre les enjeux du NLP</h1>
                                    <div class="quarto-categories">
                        <div class="quarto-category">NLP</div>
                        <div class="quarto-category">Tutoriel</div>
                      </div>
                          </div>
        
                <div>
          <div id="title-block-title-desc" class="description pt-4">
            <p>Les corpus textuels étant des objets de très grande dimension
            où le ratio signal/bruit est faible, il est nécessaire de mettre
            en oeuvre une série d’étapes de nettoyage de texte. Ce chapitre va
            explorer quelques méthodes classiques de nettoyage en s’appuyant
            sur le <em>Comte de Monte Cristo</em> d’Alexandre Dumas.</p>
          </div>
        </div>
                
        
        <div class="quarto-title-meta">

            <div>
            <div class="quarto-title-meta-heading">Author</div>
            <div class="quarto-title-meta-contents">
                     <p>Lino Galiana </p>
                  </div>
          </div>
            
            <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">July 15, 2023</p>
            </div>
          </div>
          
            
          </div>
          
        
        
        

        </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/01_intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Quelques éléments pour comprendre les enjeux du NLP</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/02_exoclean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/03_lda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Latent Dirichlet Allocation (LDA)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/04_word2vec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Méthodes de vectorisation : comptages et word embeddings</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/NLP/05_exo_supp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercices supplémentaires</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#base-dexemple" id="toc-base-dexemple" class="nav-link active" data-scroll-target="#base-dexemple">Base d’exemple</a></li>
  <li><a href="#la-particularité-des-données-textuelles" id="toc-la-particularité-des-données-textuelles" class="nav-link" data-scroll-target="#la-particularité-des-données-textuelles">La particularité des données textuelles</a>
  <ul class="collapse">
  <li><a href="#objectif" id="toc-objectif" class="nav-link" data-scroll-target="#objectif">Objectif</a></li>
  <li><a href="#méthode" id="toc-méthode" class="nav-link" data-scroll-target="#méthode">Méthode</a></li>
  </ul></li>
  <li><a href="#nettoyer-un-texte" id="toc-nettoyer-un-texte" class="nav-link" data-scroll-target="#nettoyer-un-texte">Nettoyer un texte</a>
  <ul class="collapse">
  <li><a href="#tokenisation" id="toc-tokenisation" class="nav-link" data-scroll-target="#tokenisation">Tokenisation</a></li>
  <li><a href="#retirer-les-stop-words" id="toc-retirer-les-stop-words" class="nav-link" data-scroll-target="#retirer-les-stop-words">Retirer les stop-words</a></li>
  <li><a href="#stemming" id="toc-stemming" class="nav-link" data-scroll-target="#stemming"><em>Stemming</em></a></li>
  </ul></li>
  <li><a href="#reconnaissance-des-entités-nommées" id="toc-reconnaissance-des-entités-nommées" class="nav-link" data-scroll-target="#reconnaissance-des-entités-nommées">Reconnaissance des entités nommées</a></li>
  <li><a href="#représentation-dun-texte-sous-forme-vectorielle" id="toc-représentation-dun-texte-sous-forme-vectorielle" class="nav-link" data-scroll-target="#représentation-dun-texte-sous-forme-vectorielle">Représentation d’un texte sous forme vectorielle</a></li>
  <li><a href="#références" id="toc-références" class="nav-link" data-scroll-target="#références">Références</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/linogaliana/python-datascientist/edit/master/content/NLP/01_intro.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/linogaliana/python-datascientist/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">

<!-- source: https://github.com/gadenbuie/garrickadenbuie-com/blob/main/_partials/title-block-link-buttons/title-block.html -->
<!-- source: https://raw.githubusercontent.com/spcanelon/silvia/32853dd0e70a71514b0922ee306f80ed5897f776/_partials/title-block-link-buttons/title-block.html -->
<!-- 
<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title"> 
-->
<!-- <header id="title-block-header" class="quarto-title-block default page-columns"> -->
<!-- <div class="quarto-title page-columns page-full featured-image p-4" style="background-image: url(featured.png), url(featured.jpg), url(../featured.jpg);"> -->
    

<div class="cell markdown">
<p class="badges">
<a href="https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/NLP/01_intro.ipynb" class="github"><i class="fab fa-github"></i></a>
<a href="https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/NLP/01_intro.ipynb" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter" alt="Download"></a>
<a href="https://nbviewer.jupyter.org/github/linogaliana/python-datascientist-notebooksblob/main/notebooks/NLP/01_intro.ipynb" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter" alt="nbviewer"></a>
<a href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&amp;onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&amp;init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&amp;init.personalInitArgs=%C2%ABNLP%2001_intro%C2%BB&amp;security.allowlist.enabled=false" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&amp;logoColor=orange" alt="Onyxia"></a>
<a href="https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=true&amp;onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&amp;init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&amp;init.personalInitArgs=%C2%ABNLP%2001_intro%C2%BB&amp;security.allowlist.enabled=false" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&amp;logoColor=blue" alt="Onyxia"></a><br>
<a href="https://mybinder.org/v2/gh/linogaliana/python-datascientist-notebooks/main?filepath={binder_path}" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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" alt="Binder"></a>
<a href="https://colab.research.google.com/github/linogaliana/python-datascientist-notebooks/blob/main/notebooks/NLP/01_intro.ipynb" target="_blank" rel="noopener"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
<a href="https://github.dev/linogaliana/python-datascientist-notebooks/notebooks/NLP/01_intro.ipynb" target="_blank" rel="noopener"><img src="https://img.shields.io/static/v1?logo=visualstudiocode&amp;label=&amp;message=Open%20in%20Visual%20Studio%20Code&amp;labelColor=2c2c32&amp;color=007acc&amp;logoColor=007acc" alt="githubdev"></a>
</p>
<p></p>
</div>
<p>Le <em>NLP</em> est un domaine immense de recherche. Cette page est une introduction
fort incomplète à la question. Il s’agit de montrer la logique, quelques exemples
avec <code>Python</code> <i class="fab fa-python"></i>
et s’amuser avec comme base d’exemple un livre formidable :books: :
<em>Le Comte de Monte Cristo</em>.</p>
<p>Dans le cadre de l’introduction au NLP que vous pouvez retrouver dans
les différents chapitres, nous évoquons principalement les champs suivants du NLP:</p>
<ul>
<li><em>Preprocessing</em></li>
<li>Approches <em>bag of words</em> et contextuelles (n-grams, etc.)</li>
<li><em>Topics modelling</em></li>
<li><em>Word embedding</em></li>
</ul>
<p>Cela laisse de côté des champs très actifs de recherche
du NLP, notamment l’analyse de sentiment ou les modèles de
langage (modèles GPT par exemple). Les outils découverts
dans cette partie du cours permettront, si vous le désirez,
de bénéficier d’une base solide pour approfondir tel ou tel
sujet.</p>
<section id="base-dexemple" class="level2">
<h2 class="anchored" data-anchor-id="base-dexemple">Base d’exemple</h2>
<p>La base d’exemple est le <em>Comte de Monte Cristo</em> d’Alexandre Dumas.
Il est disponible
gratuitement sur le site
<a href="http://www.gutenberg.org/ebooks/author/492">Project Gutemberg</a> comme des milliers
d’autres livres du domaine public. La manière la plus simple de le récupérer
est de télécharger avec le <em>package</em> <code>request</code> le fichier texte et le retravailler
légèrement pour ne conserver que le corpus du livre :</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib <span class="im">import</span> request</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://www.gutenberg.org/files/17989/17989-0.txt"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> request.urlopen(url)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>raw <span class="op">=</span> response.read().decode(<span class="st">'utf8'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>dumas <span class="op">=</span> raw.split(<span class="st">"*** START OF THE PROJECT GUTENBERG EBOOK LE COMTE DE MONTE-CRISTO, TOME I ***"</span>)[<span class="dv">1</span>].split(<span class="st">"*** END OF THE PROJECT GUTENBERG EBOOK LE COMTE DE MONTE-CRISTO, TOME I ***"</span>)[<span class="dv">0</span>]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_text(text):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.lower() <span class="co"># mettre les mots en minuscule</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">" "</span>.join(text.split())</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>dumas <span class="op">=</span> clean_text(dumas)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>dumas[<span class="dv">10000</span>:<span class="dv">10500</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>" mes yeux. --vous avez donc vu l'empereur aussi? --il est entré chez le maréchal pendant que j'y étais. --et vous lui avez parlé? --c'est-à-dire que c'est lui qui m'a parlé, monsieur, dit dantès en souriant. --et que vous a-t-il dit? --il m'a fait des questions sur le bâtiment, sur l'époque de son départ pour marseille, sur la route qu'il avait suivie et sur la cargaison qu'il portait. je crois que s'il eût été vide, et que j'en eusse été le maître, son intention eût été de l'acheter; mais je lu"</code></pre>
</div>
</div>
</section>
<section id="la-particularité-des-données-textuelles" class="level2">
<h2 class="anchored" data-anchor-id="la-particularité-des-données-textuelles">La particularité des données textuelles</h2>
<section id="objectif" class="level3">
<h3 class="anchored" data-anchor-id="objectif">Objectif</h3>
<p>Le <em>natural language processing</em> (NLP) ou
<em>traitement automatisé de la langue</em> (TAL) en Français,
vise à extraire de l’information de textes à partir d’une analyse statistique du contenu.
Cette définition permet d’inclure de nombreux champs d’applications au sein
du NLP (traduction, analyse de sentiment, recommandation, surveillance, etc. ) ainsi que de méthodes.</p>
<p>Cette approche implique de transformer un texte, qui est une information compréhensible par un humain, en un nombre, information appropriée pour un ordinateur et une approche statistique ou algorithmique.</p>
<p>Transformer une information textuelle en valeurs numériques propres à une analyse statistique n’est pas une tâche évidente. Les données textuelles sont <strong>non structurées</strong> puisque l’information cherchée, qui est propre à chaque analyse, est perdue au milieu d’une grande masse d’informations qui doit, de plus, être interprétée dans un certain contexte (un même mot ou une phrase n’ayant pas la même signification selon le contexte).</p>
<p>Si cette tâche n’était pas assez difficile comme ça, on peut ajouter d’autres difficultés propres à l’analyse textuelle car ces données sont :</p>
<ul>
<li>bruitées : ortographe, fautes de frappe…</li>
<li>changeantes : la langue évolue avec de nouveaux mots, sens…</li>
<li>complexes : structures variables, accords…</li>
<li>ambigues : synonymie, polysémie, sens caché…</li>
<li>propres à chaque langue : il n’existe pas de règle de passage unique entre deux langues</li>
<li>grande dimension : des combinaisons infinies de séquences de mots</li>
</ul>
</section>
<section id="méthode" class="level3">
<h3 class="anchored" data-anchor-id="méthode">Méthode</h3>
<p>L’unité textuelle peut être le mot ou encore une séquence de <em>n</em>
mots (un <em>n-gramme</em>) ou encore une chaîne de caractères (e.g.&nbsp;la
ponctuation peut être signifiante). On parle de <strong>token</strong>. L’analyse textuelle vise à transformer le texte en données
numériques manipulables.</p>
<p>On peut ensuite utiliser diverses techniques (clustering,
classification supervisée) suivant l’objectif poursuivi pour exploiter
l’information transformée. Mais les étapes de nettoyage de texte sont indispensables car sinon un algorithme sera incapable de détecter une information pertinente dans l’infini des possibles.</p>
</section>
</section>
<section id="nettoyer-un-texte" class="level2">
<h2 class="anchored" data-anchor-id="nettoyer-un-texte">Nettoyer un texte</h2>
<p>Les <em>wordclouds</em> sont des représentations graphiques assez pratiques pour visualiser
les mots les plus fréquents. Elles sont très simples à implémenter en <code>Python</code>
avec le module <code>wordcloud</code> qui permet même d’ajuster la forme du nuage à
une image :</p>
<div id="fig-wordcloud-dumas" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> wordcloud</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/NLP/book.png"</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>book_mask <span class="op">=</span> np.array(PIL.Image.<span class="bu">open</span>(io.BytesIO(requests.get(img).content)))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_wordcloud(corpus):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    wc <span class="op">=</span> wordcloud.WordCloud(background_color<span class="op">=</span><span class="st">"white"</span>, max_words<span class="op">=</span><span class="dv">2000</span>, mask<span class="op">=</span>book_mask, contour_width<span class="op">=</span><span class="dv">3</span>, contour_color<span class="op">=</span><span class="st">'steelblue'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    wc.generate(corpus)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> wc</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.imshow(make_wordcloud(dumas), interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.show()</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.savefig('word.png', bbox_inches='tight')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-wordcloud-dumas-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<pre><code>(-0.5, 1429.5, 783.5, -0.5)</code></pre>
<figcaption class="figure-caption">(a) Nuage de mot produit à partir du Comte de Monte Cristo</figcaption>
</figure>
</div>
<div class="cell-output cell-output-display">
<div id="fig-wordcloud-dumas-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="01_intro_files/figure-html/fig-wordcloud-dumas-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="01_intro_files/figure-html/fig-wordcloud-dumas-output-2.png" width="540" height="305" class="figure-img"></a></p>
<figcaption class="figure-caption">(b)</figcaption>
</figure>
</div>
</div>
<figcaption class="figure-caption">Figure&nbsp;1: <strong>?(caption)</strong></figcaption>
</figure>
</div>
<p>Cela montre clairement qu’il est nécessaire de nettoyer notre texte. Le nom
du personnage principal, Dantès, est ainsi masqué par un certain nombre
d’articles ou mots de liaison qui perturbent l’analyse. Ces mots sont des
<em>stop-words</em>. La librairie <code>NLTK</code> (<em>Natural Language ToolKit</em>), librairie
de référence dans le domaine du NLP, permet de facilement retirer ces
stopwords (cela pourrait également être fait avec
la librairie plus récente, <code>spaCy</code>). Avant cela, il est nécessaire
de transformer notre texte en le découpant par unités fondamentales (les tokens).</p>
<p>Les exemples suivants, extraits de <span class="citation" data-cites="galianafuzzy">Galiana and Castillo (<a href="#ref-galianafuzzy" role="doc-biblioref">2022</a>)</span>, montrent l’intérêt du
nettoyage de textes lorsqu’on désire comparer des corpus
entre eux. En l’occurrence, il s’agit de comparer un corpus de
noms de produits dans des collectes automatisées de produits
de supermarché (<em>scanner-data</em>) avec des noms de produits
dans les données de l’<code>OpenFoodFacts</code>, une base de données
contributive. Sans nettoyage, le bruit l’emporte sur le signal
et il est impossible de déceler des similarités entre les jeux
de données. Le nettoyage permet d’harmoniser
un peu ces jeux de données pour avoir une chance d’être en
mesure de les comparer.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="wordcloud_openfood_start.png" class="lightbox" title="OpenFoodFacts avant nettoyage" data-gallery="quarto-lightbox-gallery-2"><img src="wordcloud_openfood_start.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption"><code>OpenFoodFacts</code> avant nettoyage</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="wordcloud_relevanc_start.png" class="lightbox" title="Scanner-data avant nettoyage" data-gallery="quarto-lightbox-gallery-3"><img src="wordcloud_relevanc_start.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption"><em>Scanner-data</em> avant nettoyage</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="wordcloud_openfood_clean.png" class="lightbox" title="OpenFoodFacts après nettoyage" data-gallery="quarto-lightbox-gallery-4"><img src="wordcloud_openfood_clean.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption"><code>OpenFoodFacts</code> après nettoyage</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="wordcloud_relevanc_clean.png" class="lightbox" title="Scanner-data après nettoyage" data-gallery="quarto-lightbox-gallery-5"><img src="wordcloud_relevanc_clean.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption"><em>Scanner-data</em> après nettoyage</figcaption>
</figure>
</div>
</div>
</div>
<section id="tokenisation" class="level3">
<h3 class="anchored" data-anchor-id="tokenisation">Tokenisation</h3>
<div class="cell markdown">
<div class="alert alert-warning" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-lightbulb"></i> Hint</h3>
<p>Lors de la première utilisation de <code>NLTK</code>, il est nécessaire de télécharger
quelques éléments nécessaires à la tokenisation, notamment la ponctuation.
Pour cela, il est recommandé d’utiliser la commande suivante :</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to /github/home/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>True</code></pre>
</div>
</div>
<p>La tokenisation consiste à découper un texte en morceaux. Ces morceaux
pourraient être des phrases, des chapitres, des n-grammes ou des mots. C’est
cette dernière option que l’on va choisir, plus simple pour retirer les
<em>stopwords</em> :</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> nltk.word_tokenize(dumas, language<span class="op">=</span><span class="st">'french'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>words[<span class="dv">1030</span>:<span class="dv">1050</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>['que',
 'voulez-vous',
 ',',
 'monsieur',
 'edmond',
 ',',
 'reprit',
 "l'armateur",
 'qui',
 'paraissait',
 'se',
 'consoler',
 'de',
 'plus',
 'en',
 'plus',
 ',',
 'nous',
 'sommes',
 'tous']</code></pre>
</div>
</div>
<p>On remarque que les mots avec apostrophes sont liés en un seul, ce qui est
peut-être faux sur le plan de la grammaire mais peu avoir un sens pour une
analyse statistique. Il reste des signes de ponctuation qu’on peut éliminer
avec la méthode <code>isalpha</code>:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> [word <span class="cf">for</span> word <span class="kw">in</span> words <span class="cf">if</span> word.isalpha()]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>words[<span class="dv">1030</span>:<span class="dv">1050</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>['assez',
 'sombre',
 'obséquieux',
 'envers',
 'ses',
 'supérieurs',
 'insolent',
 'envers',
 'ses',
 'subordonnés',
 'aussi',
 'outre',
 'son',
 'titre',
 'comptable',
 'qui',
 'est',
 'toujours',
 'un',
 'motif']</code></pre>
</div>
</div>
<p>Comme indiqué ci-dessus, pour télécharger
le corpus de ponctuation, il est
nécessaire d’exécuter la ligne de
commande suivante :</p>
</section>
<section id="retirer-les-stop-words" class="level3">
<h3 class="anchored" data-anchor-id="retirer-les-stop-words">Retirer les stop-words</h3>
<p>Le jeu de données est maintenant propre. On peut désormais retirer les
mots qui n’apportent pas de sens et servent seulement à faire le
lien entre deux prépositions. On appelle ces mots des
<em>stop words</em> dans le domaine du NLP.</p>
<div class="cell markdown">
<div class="alert alert-warning" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-lightbulb"></i> Hint</h3>
<p>Lors de la première utilisation de <code>NLTK</code>, il est nécessaire de télécharger
les stopwords.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Comme indiqué ci-dessus, pour télécharger
le corpus de stopwords<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, il est
nécessaire d’exécuter la ligne de
commande suivante :</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package stopwords to /github/home/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stopwords.words(<span class="st">"french"</span>))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'french'</span>))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> [w <span class="cf">for</span> w <span class="kw">in</span> words <span class="cf">if</span> <span class="kw">not</span> w <span class="kw">in</span> stop_words]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(words[<span class="dv">1030</span>:<span class="dv">1050</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']
['celui', 'dantès', 'a', 'déposé', 'passant', 'comment', 'paquet', 'déposer', 'danglars', 'rougit', 'passais', 'devant', 'porte', 'capitaine', 'entrouverte', 'vu', 'remettre', 'paquet', 'cette', 'lettre']</code></pre>
</div>
</div>
<p>Ces retraitements commencent à porter leurs fruits puisque des mots ayant plus
de sens commencent à se dégager, notamment les noms des personnages
(Fernand, Mercédès, Villefort, etc.)</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>wc <span class="op">=</span> make_wordcloud(<span class="st">' '</span>.join(words))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(wc, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(-0.5, 1429.5, 783.5, -0.5)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="01_intro_files/figure-html/cell-10-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="01_intro_files/figure-html/cell-10-output-2.png" width="540" height="305" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="stemming" class="level3">
<h3 class="anchored" data-anchor-id="stemming"><em>Stemming</em></h3>
<p>Pour réduire la complexité d’un texte, on peut tirer partie de
<em>“classes d’équivalence”</em> : on peut
considérer que différentes formes d’un même mot (pluriel,
singulier, conjugaison) sont équivalentes et les remplacer par une
même forme dite canonique. Il existe deux approches dans le domaine :</p>
<ul>
<li>la <strong>lemmatisation</strong> qui requiert la connaissance des statuts
grammaticaux (exemple : chevaux devient cheval)</li>
<li>la <strong>racinisation</strong> (<em>stemming</em>) plus fruste mais plus rapide, notamment
en présence de fautes d’orthographes. Dans ce cas, chevaux peut devenir chev
mais être ainsi confondu avec chevet ou cheveux</li>
</ul>
<p>La racinisation est plus simple à mettre en oeuvre car elle peut s’appuyer sur
des règles simples pour extraire la racine d’un mot.</p>
<p>Pour réduire un mot dans sa forme “racine”, c’est-à-dire en s’abstrayant des
conjugaisons ou variations comme les pluriels, on applique une méthode de
<em>stemming</em>. Le but du <em>stemming</em> est de regrouper de
nombreuses variantes d’un mot comme un seul et même mot.
Par exemple, une fois que l’on applique un stemming, “chats” et “chat”
deviennent un même mot.</p>
<p>Cette approche a l’avantage de réduire la taille du vocabulaire à maîtriser
pour l’ordinateur et le modélisateur. Il existe plusieurs algorithmes de
<em>stemming</em>, notamment le <em>Porter Stemming Algorithm</em> ou le
<em>Snowball Stemming Algorithm</em>. Nous pouvons utiliser ce dernier en Français :</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.snowball <span class="im">import</span> SnowballStemmer</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>stemmer <span class="op">=</span> SnowballStemmer(language<span class="op">=</span><span class="st">'french'</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>stemmed <span class="op">=</span> [stemmer.stem(word) <span class="cf">for</span> word <span class="kw">in</span> words]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stemmed[<span class="dv">1030</span>:<span class="dv">1050</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['celui', 'dantes', 'a', 'dépos', 'pass', 'comment', 'paquet', 'dépos', 'danglar', 'roug', 'pass', 'dev', 'port', 'capitain', 'entrouvert', 'vu', 'remettr', 'paquet', 'cet', 'lettr']</code></pre>
</div>
</div>
<p>A ce niveau, les mots commencent à être moins intelligibles par un humain.
La machine prendra le relais, on lui a préparé le travail</p>
<div class="cell markdown">
<div class="alert alert-info" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-comment"></i> Note</h3>
<p>Il existe aussi le <em>stemmer</em> suivant :</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.snowball <span class="im">import</span> FrenchStemmer</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>stemmer <span class="op">=</span> FrenchStemmer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
</section>
<section id="reconnaissance-des-entités-nommées" class="level2">
<h2 class="anchored" data-anchor-id="reconnaissance-des-entités-nommées">Reconnaissance des entités nommées</h2>
<p>Cette étape n’est pas une étape de préparation mais illustre la capacité
des librairies <code>Python</code> a extraire du sens d’un texte. La librairie
<code>spaCy</code> permet de faire de la reconnaissance d’entités nommées, ce qui peut
être pratique pour extraire rapidement certains personnages de notre oeuvre.</p>
<div class="cell markdown">
<div class="alert alert-info" role="alert">
<h3 class="alert-heading anchored"><i class="fa-solid fa-comment"></i>La librairie spaCy</h3>
<p><code>NTLK</code> est la librairie historique d’analyse textuelle en <code>Python</code>. Elle existe
depuis les années 1990. L’utilisation industrielle du NLP dans le monde
de la <em>data science</em> est néanmoins plus récente et doit beaucoup à la collecte
accrue de données non structurées par les réseaux sociaux. Cela a amené à
un renouvelement du champ du NLP, tant dans le monde de la recherche que dans
sa mise en application dans l’industrie de la donnée.</p>
<p>Le <em>package</em> <a href="https://spacy.io/"><code>spaCy</code></a> est l’un des packages qui a permis
cette industrialisation des méthodes de NLP. Conçu autour du concept
de <em>pipelines</em> de données, il est beaucoup plus pratique à mettre en oeuvre
pour une chaîne de traitement de données textuelles mettant en oeuvre
plusieurs étapes de transformation des données.</p>
</div>
</div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install deplacy</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#!python -m spacy download fr_core_news_sm</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>nlp<span class="op">=</span>spacy.load(<span class="st">"fr_core_news_sm"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(dumas)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spacy <span class="im">import</span> displacy</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>displacy.render(doc, style<span class="op">=</span><span class="st">"ent"</span>, jupyter<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="représentation-dun-texte-sous-forme-vectorielle" class="level2">
<h2 class="anchored" data-anchor-id="représentation-dun-texte-sous-forme-vectorielle">Représentation d’un texte sous forme vectorielle</h2>
<p>Une fois nettoyé, le texte est plus propice à une représentation vectorielle.
En fait, implicitement, on a depuis le début adopté une démarche <em>bag of words</em>.
Il s’agit d’une représentation, sans souci de contexte (ordre des mots, contexte d’utilisation),
où chaque <em>token</em> représente un élément dans un vocabulaire de taille <span class="math inline">\(|V|\)</span>.
On peut ainsi avoir une représentation matricielle les occurrences de
chaque <em>token</em> dans plusieurs documents (par exemple plusieurs livres,
chapitres, etc.) pour, par exemple, en déduire une forme de similarité.</p>
<p>Afin de réduire la dimension de la matrice <em>bag of words</em>,
on peut s’appuyer sur des pondérations.
On élimine ainsi certains mots très fréquents ou au contraire très rares.
La pondération la plus simple est basée sur la fréquence des mots dans le document.
C’est l’objet de la métrique <strong>tf-idf</strong> (term frequency - inverse document frequency)
abordée dans un prochain chapitre.</p>
</section>
<section id="références" class="level2">




</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Références</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-galianafuzzy" class="csl-entry" role="listitem">
Galiana, Lino, and Milena Suarez Castillo. 2022. <span>“Fuzzy Matching on Big-Data an Illustration with Scanner Data and Crowd-Sourced Nutritional Data.”</span>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Le corpus de <em>stop-words</em> de <code>NLTK</code>
est relativement limité. Il est recommandé
de privilégier celui de <code>spaCy</code>, plus
complet, pour éliminer plus de mots
valises.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@book{galiana2023,
  author = {Galiana, Lino},
  title = {Python Pour La Data Science},
  date = {2023},
  url = {https://pythonds.linogaliana.fr/},
  doi = {10.5281/zenodo.8229676},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-galiana2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Galiana, Lino. 2023. <em>Python Pour La Data Science</em>. <a href="https://doi.org/10.5281/zenodo.8229676">https://doi.org/10.5281/zenodo.8229676</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="linogaliana/python-datascientist" data-repo-id="MDEwOlJlcG9zaXRvcnkyODAxNjE2Nzc=" data-category="General" data-category-id="DIC_kwDOELLtjc4B-5TX" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../content/NLP/index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduction</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../content/NLP/02_exoclean.html" class="pagination-link">
        <span class="nav-page-text">Nettoyer un texte: des exercices pour découvrir l’approche bag-of-words</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Python pour la <em>data science</em>, Lino Galiana.<br>
Licence <i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i><br>
Code source disponible sur <a href="https://github.com/linogaliana/python-datascientist"><code>Github</code></a></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">Site construit avec <i class="fa-brands fa-python" aria-label="python"></i> et <a href="https://quarto.org/"><code>Quarto</code></a><br>
Inspiration pour la mise en forme du site <a href="https://www.andreashandel.com">ici</a><br>
<a href="https://github.com/linogaliana/python-datascientist">Code source disponible sur <i class="fa-brands fa-github" aria-label="github"></i> <code>GitHub</code></a></div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","selector":".lightbox","descPosition":"bottom","openEffect":"zoom","loop":true});</script>



</body></html>