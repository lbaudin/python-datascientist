[
  {
    "objectID": "content/manipulation/04c_API_TP.html",
    "href": "content/manipulation/04c_API_TP.html",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "",
    "text": "La partie utilisant l‚ÄôAPI DVF n‚Äôest plus √† jour, elle sera mise √† jour prochainement"
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#introduction-quest-ce-quune-api",
    "href": "content/manipulation/04c_API_TP.html#introduction-quest-ce-quune-api",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Introduction : Qu‚Äôest-ce qu‚Äôune API ?",
    "text": "Introduction : Qu‚Äôest-ce qu‚Äôune API ?\n\nD√©finition\nPour expliquer le principe d‚Äôune API, je vais reprendre le d√©but de\nla fiche d√©di√©e dans la documentation collaborative\nutilitR que je recommande de lire :\n\nUne Application Programming Interface (ou API) est une interface de programmation qui permet d‚Äôutiliser une application existante pour restituer des donn√©es. Le terme d‚ÄôAPI peut √™tre para√Ætre intimidant, mais il s‚Äôagit simplement d‚Äôune fa√ßon de mettre √† disposition des donn√©es : plut√¥t que de laisser l‚Äôutilisateur consulter directement des bases de donn√©es (souvent volumineuses et complexes), l‚ÄôAPI lui propose de formuler une requ√™te qui est trait√©e par le serveur h√©bergeant la base de donn√©es, puis de recevoir des donn√©es en r√©ponse √† sa requ√™te.\nD‚Äôun point de vue informatique, une API est une porte d‚Äôentr√©e clairement identifi√©e par laquelle un logiciel offre des services √† d‚Äôautres logiciels (ou utilisateurs). L‚Äôobjectif d‚Äôune API est de fournir un point d‚Äôacc√®s √† une fonctionnalit√© qui soit facile √† utiliser et qui masque les d√©tails de la mise en oeuvre. Par exemple, l‚ÄôAPI Sirene permet de r√©cup√©rer la raison sociale d‚Äôune entreprise √† partir de son identifiant Siren en interrogeant le r√©f√©rentiel disponible sur Internet directement depuis un script R, sans avoir √† conna√Ætre tous les d√©tails du r√©pertoire Sirene.\n√Ä l‚ÄôInsee comme ailleurs, la connexion entre les bases de donn√©es pour les nouveaux projets tend √† se r√©aliser par des API. L‚Äôacc√®s √† des donn√©es par des API devient ainsi de plus en plus commun et est amen√© √† devenir une comp√©tence de base de tout utilisateur de donn√©es.\nutilitR\n\n\n\nAvantages des API\nA nouveau, citons la documentation utilitR\nLes API pr√©sentent de multiples avantages :\n\n\nLes API rendent les programmes plus reproductibles. En effet, gr√¢ce aux API, il est possible de mettre √† jour facilement les donn√©es utilis√©es par un programme si celles-ci √©voluent. Cette flexibilit√© accrue pour l‚Äôutilisateur √©vite au producteur de donn√©es d‚Äôavoir √† r√©aliser de multiples extractions, et r√©duit le probl√®me de la coexistence de versions diff√©rentes des donn√©es.\nGr√¢ce aux API, l‚Äôutilisateur peut extraire facilement une petite partie d‚Äôune base de donn√©es plus cons√©quente.\nLes API permettent de mettre √† disposition des donn√©es tout en limitant le nombre de personnes ayant acc√®s aux bases de donn√©es elles-m√™mes.\nGr√¢ce aux API, il est possible de proposer des services sur mesure pour les utilisateurs (par exemple, un acc√®s sp√©cifique pour les gros utilisateurs).\n\nutilitR\n\nL‚Äôutilisation accrue d‚ÄôAPI dans le cadre de strat√©gies open-data est l‚Äôun\ndes piliers des 15 feuilles de route minist√©rielles\nen mati√®re d‚Äôouverture, de circulation et de valorisation des donn√©es publiques.\n\n\nUtilisation des API\nCitons encore une fois\nla documentation utilitR\n\nUne API peut souvent √™tre utilis√©e de deux fa√ßons : par une interface Web, et par l‚Äôinterm√©diaire d‚Äôun logiciel (R, Python‚Ä¶). Par ailleurs, les API peuvent √™tre propos√©es avec un niveau de libert√© variable pour l‚Äôutilisateur :\n\nsoit en libre acc√®s (l‚Äôutilisation n‚Äôest pas contr√¥l√©e et l‚Äôutilisateur peut utiliser le service comme bon lui semble)‚ÄØ;\nsoit via la g√©n√©ration d‚Äôun compte et d‚Äôun jeton d‚Äôacc√®s qui permettent de s√©curiser l‚Äôutilisation de l‚ÄôAPI et de limiter le nombre de requ√™tes.\n\nutilitR\n\nDe nombreuses API n√©cessitent une authentification, c‚Äôest-√†-dire un\ncompte utilisateur afin de pouvoir acc√©der aux donn√©es.\nDans un premier temps,\nnous regarderons exclusivement les API ouvertes sans restriction d‚Äôacc√®s.\nCertains exercices et exemples permettront n√©anmoins d‚Äôessayer des API\navec restrictions d‚Äôacc√®s."
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#requ√™ter-une-api",
    "href": "content/manipulation/04c_API_TP.html#requ√™ter-une-api",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Requ√™ter une API",
    "text": "Requ√™ter une API\n\nPrincipe g√©n√©ral\n\nL‚Äôutilisation de l‚Äôinterface Web est utile dans une d√©marche exploratoire mais trouve rapidement ses limites, notamment lorsqu‚Äôon consulte r√©guli√®rement l‚ÄôAPI. L‚Äôutilisateur va rapidement se rendre compte qu‚Äôil est beaucoup plus commode d‚Äôutiliser une API via un logiciel de traitement pour automatiser la consultation ou pour r√©aliser du t√©l√©chargement de masse. De plus, l‚Äôinterface Web n‚Äôexiste pas syst√©matiquement pour toutes les API.\nLe mode principal de consultation d‚Äôune API consiste √† adresser une requ√™te √† cette API via un logiciel adapt√© (R, Python, Java‚Ä¶). Comme pour l‚Äôutilisation d‚Äôune fonction, l‚Äôappel d‚Äôune API comprend des param√®tres qui sont d√©taill√©es dans la documentation de l‚ÄôAPI.\nutilitR\n\nVoici les √©l√©ments importants √† avoir en t√™te sur les requ√™tes (j‚Äôemprunte encore\n√† utilitR) :\n\nLe point d‚Äôentr√©e d‚Äôun service offert par une API se pr√©sente sous la forme d‚Äôune URL (adresse web).\nChaque service propos√© par une API a sa propre URL. Par exemple, dans le cas de l‚ÄôOpenFood Facts,\nl‚ÄôURL √† utiliser pour obtenir des informations sur un produit particulier (l‚Äôidentifiant 737628064502)\nest https://world.openfoodfacts.org/api/v0/product/737628064502.json\nCette URL doit √™tre compl√©t√©e avec diff√©rents param√®tres qui pr√©cisent la requ√™te (par exemple l‚Äôidentifiant Siren). Ces param√®tres viennent s‚Äôajouter √† l‚ÄôURL, souvent √† la suite de ?. Chaque service propos√© par une API a ses propres param√®tres, d√©taill√©s dans la documentation.\nLorsque l‚Äôutilisateur soumet sa requ√™te, l‚ÄôAPI lui renvoie une r√©ponse structur√©e contenant l‚Äôensemble des informations demand√©es. Le r√©sultat envoy√© par une API est majoritairement aux formats JSON ou XML (deux formats dans lesquels les informations sont hi√©rarchis√©es de mani√®re emboit√©e). Plus rarement, certains services proposent une information sous forme plate (de type csv).\n\nDu fait de la dimension hi√©rarchique des formats JSON ou XML,\nle r√©sultat n‚Äôest pas toujours facile √† r√©cup√©rer mais\nPython propose d‚Äôexcellents outils pour cela (meilleurs que ceux de R).\nCertains packages, notamment json, facilitent l‚Äôextraction de champs d‚Äôune sortie d‚ÄôAPI.\nDans certains cas, des packages sp√©cifiques √† une API ont √©t√© cr√©√©s pour simplifier l‚Äô√©criture d‚Äôune requ√™te ou la r√©cup√©ration du r√©sultat. Par exemple, le package\npynsee\npropose des options qui seront retranscrites automatiquement dans l‚ÄôURL de\nrequ√™te pour faciliter le travail sur les donn√©es Insee.\n\n\nIllustration avec une API de l‚ÄôAdeme pour obtenir des diagnostics energ√©tiques\nLe diagnostic de performance √©nerg√©tique (DPE)\nrenseigne sur la performance √©nerg√©tique d‚Äôun logement ou d‚Äôun b√¢timent,\nen √©valuant sa consommation d‚Äô√©nergie et son impact en terme d‚Äô√©missions de gaz √† effet de serre.\nLes donn√©es des performances √©nerg√©tiques des b√¢timents sont\nmises √† disposition par l‚ÄôAdeme.\nComme ces donn√©es sont relativement\nvolumineuses, une API peut √™tre utile lorsqu‚Äôon ne s‚Äôint√©resse\nqu‚Äô√† un sous-champ des donn√©es.\nUne documentation et un espace de test de l‚ÄôAPI sont disponibles\nsur le site API GOUV1.\nSupposons qu‚Äôon d√©sire r√©cup√©rer une centaine de valeurs pour la commune\nde Villieu-Loyes-Mollon dans l‚ÄôAin (code Insee 01450).\nL‚ÄôAPI comporte plusieurs points d‚Äôentr√©e. Globalement, la racine\ncommune est:\n\nhttps://koumoul.com/data-fair/api/v1/datasets/dpe-france\n\nEnsuite, en fonction de l‚ÄôAPI d√©sir√©e, on va ajouter des √©l√©ments\n√† cette racine. En l‚Äôoccurrence, on va utiliser\nl‚ÄôAPI field qui permet de r√©cup√©rer des lignes en fonction d‚Äôun\nou plusieurs crit√®res (pour nous, la localisation g√©ographique):\nL‚Äôexemple donn√© dans la documentation technique est\n\nGET https://koumoul.com/data-fair/api/v1/datasets/dpe-france/values/{field}\n\nce qui en Python se traduira par l‚Äôutilisation de la m√©thode get du\npackage Request\nsur un url dont la structure est la suivante :\n\nil commencera par https://koumoul.com/data-fair/api/v1/datasets/dpe-france/values/ ;\nil sera ensuite suivi par des param√®tres de recherche. Le champ {field}\ncommence ainsi g√©n√©ralement par un ? qui permet ensuite de sp√©cifier des param√®tres\nsous la forme nom_parameter=value\n\nA la lecture de la documentation, les premiers param√®tres qu‚Äôon d√©sire :\n\nLe nombre de pages, ce qui nous permet d‚Äôobtenir un certain nombre d‚Äô√©chos. On\nva seulement r√©cup√©rer 10 pages ce qui correspond √† une centaine d‚Äô√©chos. On va\nn√©anmoins pr√©ciser qu‚Äôon veut 100 √©chos\nLe format de sortie. On va privil√©gier le JSON qui est un format standard dans le\nmonde des API. Python offre beaucoup de flexibilit√© gr√¢ce √† l‚Äôun de\nses objets de base, √† savoir le dictionnaire (type dict), pour manipuler de tels\nfichiers\nLe code commune des donn√©es qu‚Äôon d√©sire obtenir. Comme on l‚Äôa √©voqu√©,\non va r√©cup√©rer les donn√©es dont le code commune est 01450. D‚Äôapr√®s la doc,\nil convient de passer le code commune sous le format:\ncode_insee_commune_actualise:{code_commune}. Pour √©viter tout risque de\nmauvais formatage, on va utiliser %3A pour signifier :, %2A pour signifier * et\n%22 pour signifier \".\nD‚Äôautres param√®tres annexes, sugg√©r√©s par la documentation\n\nCela nous donne ainsi un URL dont la structure est la suivante :\n\ncode_commune = \"01450\"\nsize = 100\napi_root = \"https://koumoul.com/data-fair/api/v1/datasets/dpe-france/lines\"\nurl_api = f\"{api_root}?page=1&after=10&format=json&q_mode=simple&qs=code_insee_commune_actualise\" + \"%3A%22\" + f\"{code_commune}\" + \"%22\" + f\"&size={size}&select=\" + \"%2A&sampling=neighbors\"\n\nSi vous introduisez cet URL dans votre navigateur, vous devriez aboutir\nsur un JSON non format√©2. En Python,\non peut utiliser requests pour r√©cup√©rer les donn√©es3 :\n\nimport requests\nimport pandas as pd\n\nreq = requests.get(url_api)\nwb = req.json()\n\nPrenons par exemple les 1000 premiers caract√®res du r√©sultat, pour se donner\nune id√©e du r√©sultat et se convaincre que notre filtre au niveau\ncommunal est bien pass√© :\nprint(req.content[:1000])\nb‚Äô{‚Äútotal‚Äù: 121,‚Äúnext‚Äù: ‚Äúhttps://koumoul.com/data-fair/api/v1/datasets/dpe-france/lines?after=102721&format=json&q_mode=simple&qs=code_insee_commune_actualise%3A%2201450%22&size=100&select=*&sampling=neighbors‚Äù,‚Äúresults‚Äù: [\\n {‚Äúclasse_consommation_energie‚Äù: ‚ÄúD‚Äù,‚Äútr001_modele_dpe_type_libelle‚Äù: ‚ÄúVente‚Äù,‚Äúannee_construction‚Äù: 1947,‚Äú_geopoint‚Äù: ‚Äú45.925922,5.229964‚Äù,‚Äúlatitude‚Äù: 45.925922,‚Äúsurface_thermique_lot‚Äù: 117.16,‚Äú_i‚Äù: 487,‚Äútr002_type_batiment_description‚Äù: ‚ÄúMaison Individuelle‚Äù,‚Äúgeo_adresse‚Äù: ‚ÄúRue de la Brugni8re 01800 Villieu-Loyes-Mollon‚Äù,‚Äú_rand‚Äù: 23215,‚Äúcode_insee_commune_actualise‚Äù: ‚Äú01450‚Äù,‚Äúestimation_ges‚Äù: 53,‚Äúgeo_score‚Äù: 0.4,‚Äúclasse_estimation_ges‚Äù: ‚ÄúE‚Äù,‚Äúnom_methode_dpe‚Äù: ‚ÄúM9thode Facture‚Äù,‚Äútv016_departement_code‚Äù: ‚Äú01‚Äù,‚Äúconsommation_energie‚Äù: 178,‚Äúdate_etablissement_dpe‚Äù: ‚Äú2013-06-13‚Äù,‚Äúlongitude‚Äù: 5.229964,‚Äú_score‚Äù: null,‚Äô\nIci, il n‚Äôest m√™me pas n√©cessaire en premi√®re approche\nd‚Äôutiliser le package json, l‚Äôinformation\n√©tant d√©j√† tabul√©e dans l‚Äô√©cho renvoy√© (on a la m√™me information pour tous les pays):\nOn peut donc se contenter de Pandas pour transformer nos donn√©es en\nDataFrame et Geopandas pour convertir en donn√©es\ng√©ographiques :\n\nimport pandas as pandas\nimport geopandas as gpd\n\ndef get_dpe_from_url(url):\n\n    req = requests.get(url)\n    wb = req.json()\n    df = pd.json_normalize(wb[\"results\"])\n\n    dpe = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs = 4326)\n    dpe = dpe.dropna(subset = ['longitude', 'latitude'])\n\n    return dpe\n\ndpe = get_dpe_from_url(url_api)\ndpe.head(2)\n\n/opt/mamba/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning:\n\nThe Shapely GEOS version (3.12.0-CAPI-1.18.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n\n/tmp/ipykernel_220/2008334648.py:2: UserWarning:\n\nShapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n\nimport os\nos.environ['USE_PYGEOS'] = '0'\nimport geopandas\n\nIn a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n\n\n\n\n\n\n\n\n\n\nclasse_consommation_energie\ntr001_modele_dpe_type_libelle\nannee_construction\n_geopoint\nlatitude\nsurface_thermique_lot\n_i\ntr002_type_batiment_description\ngeo_adresse\n_rand\n...\nclasse_estimation_ges\nnom_methode_dpe\ntv016_departement_code\nconsommation_energie\ndate_etablissement_dpe\nlongitude\n_score\n_id\nversion_methode_dpe\ngeometry\n\n\n\n\n0\nD\nVente\n1947\n45.925922,5.229964\n45.925922\n117.16\n487\nMaison Individuelle\nRue de la Brugni√®re 01800 Villieu-Loyes-Mollon\n23215\n...\nE\nM√©thode Facture\n01\n178.00\n2013-06-13\n5.229964\nNone\n04JZNel3WCJYcfsHpCcHv\nNaN\nPOINT (5.22996 45.92592)\n\n\n2\nD\nNeuf\n2006\n45.923421,5.223777\n45.923421\n90.53\n689\nMaison Individuelle\nChemin du Pont-vieux 01800 Villieu-Loyes-Mollon\n401672\n...\nC\nFACTURE - DPE\n01\n227.99\n2013-06-11\n5.223777\nNone\nrkdV2lJn2wxaidVBaHBFY\nV2012\nPOINT (5.22378 45.92342)\n\n\n\n\n2 rows √ó 23 columns\n\n\n\nEssayons de repr√©senter sur une carte ces DPE avec les\nann√©es de construction des logements.\nAvec Folium, on obtient la carte interactive suivante :\n\nimport seaborn as sns\nimport folium\n\npalette = sns.color_palette(\"coolwarm\", 8)\n\ndef interactive_map_dpe(dpe):\n\n    # convert in number\n    dpe['color'] = [ord(dpe.iloc[i]['classe_consommation_energie'].lower()) - 96 for i in range(len(dpe))]\n    dpe = dpe.loc[dpe['color']&lt;=7]\n    dpe['color'] = [palette.as_hex()[x] for x in dpe['color']]\n\n\n    center = dpe[['latitude', 'longitude']].mean().values.tolist()\n    sw = dpe[['latitude', 'longitude']].min().values.tolist()\n    ne = dpe[['latitude', 'longitude']].max().values.tolist()\n\n    m = folium.Map(location = center, tiles='OpenStreetMap')\n\n    # I can add marker one by one on the map\n    for i in range(0,len(dpe)):\n        folium.Marker([dpe.iloc[i]['latitude'], dpe.iloc[i]['longitude']],\n                    popup=f\"Ann√©e de construction: {dpe.iloc[i]['annee_construction']}, &lt;br&gt;DPE: {dpe.iloc[i]['classe_consommation_energie']}\",\n                    icon=folium.Icon(color=\"black\", icon=\"home\", icon_color = dpe.iloc[i]['color'])).add_to(m)\n\n    m.fit_bounds([sw, ne])\n\n    return m\n\nm = interactive_map_dpe(dpe)\n\n/opt/mamba/lib/python3.9/site-packages/geopandas/geodataframe.py:1443: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n# Afficher la carte\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nUn catalogue incomplet d‚ÄôAPI existantes\nDe plus en plus de sites mettent des API √† disposition des d√©veloppeurs et autres curieux.\nPour en citer quelques-unes tr√®s connues :\n\nTwitter  : https://dev.twitter.com/rest/public\nFacebook  : https://developers.facebook.com/\nInstagram  : https://www.instagram.com/developer/\nSpotify  : https://developer.spotify.com/web-api/\n\nCependant, il est int√©ressant de ne pas se restreindre √† celles-ci dont les\ndonn√©es ne sont pas toujours les plus int√©ressantes. Beaucoup\nde producteurs de donn√©es, priv√©s comme publics, mettent √† disposition\nleurs donn√©es sous forme d‚ÄôAPI\n\nAPI.gouv: beaucoup d‚ÄôAPI officielles de l‚ÄôEtat fran√ßais\net acc√®s √† de la documentation\nInsee: https://api.insee.fr/catalogue/ et pynsee\nPole Emploi : https://www.emploi-store-dev.fr/portail-developpeur-cms/home.html\nSNCF : https://data.sncf.com/api\nBanque Mondiale : https://datahelpdesk.worldbank.org/knowledgebase/topics/125589"
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#lapi-dvf-acc√©der-√†-des-donn√©es-de-transactions-immobili√®res-simplement",
    "href": "content/manipulation/04c_API_TP.html#lapi-dvf-acc√©der-√†-des-donn√©es-de-transactions-immobili√®res-simplement",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "L‚ÄôAPI DVF : acc√©der √† des donn√©es de transactions immobili√®res simplement",
    "text": "L‚ÄôAPI DVF : acc√©der √† des donn√©es de transactions immobili√®res simplement\n‚ö†Ô∏è Cette partie n√©cessite une mise √† jour pour privil√©gier l‚ÄôAPI DVF du Cerema\nLe site DVF (demandes de valeurs fonci√®res) permet de visualiser toutes les donn√©es relatives aux mutations √† titre on√©reux (ventes de maisons, appartements, garages‚Ä¶) r√©alis√©es durant les 5 derni√®res ann√©es.\nUn site de visualisation est disponible sur https://app.dvf.etalab.gouv.fr/.\nCe site est tr√®s complet quand il s‚Äôagit de conna√Ætre le prix moyen au m√®tre\ncarr√© d‚Äôun quartier ou de comparer des r√©gions entre elles.\nL‚ÄôAPI DVF permet d‚Äôaller plus loin afin de r√©cup√©rer les r√©sultats dans\nun logiciel de traitement de donn√©es. Elle a √©t√© r√©alis√©e par\nChristian Quest et le code\nsource est disponible sur Github .\nLes crit√®res de recherche sont les suivants :\n- code_commune = code INSEE de la commune (ex: 94068)\n- section = section cadastrale (ex: 94068000CQ)\n- numero_plan = identifiant de la parcelle, (ex: 94068000CQ0110)\n- lat + lon + dist (optionnel): pour une recherche g√©ographique, dist est par d√©faut un rayon de 500m\n- code_postal\nLes filtres de s√©lection compl√©mentaires :\n- nature_mutation (Vente, etc)\n- type_local (Maison, Appartement, Local, D√©pendance)\nLes requ√™tes sont de la forme : http://api.cquest.org/dvf?code_commune=29168.\n\n\n Exercice 1 : Exploiter l'API DVF\n\nRechercher toutes les transactions existantes dans DVF √† Plogoff (code commune 29168, en Bretagne).\nAfficher les cl√©s du JSON et en d√©duire le nombre de transactions r√©pertori√©es.\nN‚Äôafficher que les transactions portant sur des maisons.\nUtiliser l‚ÄôAPI geo pour\nr√©cup√©rer le d√©coupage communal de la ville de Plogoff\nRepr√©senter l‚Äôhistogramme des prix de vente\n\nN‚Äôh√©sitez pas √† aller plus loin en jouant sur des variables de\ngroupes par exemple\n\n\nLe r√©sultat de la question 2 devrait\nressembler au DataFrame suivant:\nL‚Äôhistogramme des prix de vente (question 4) aura l‚Äôaspect suivant:\nOn va faire une carte des ventes en affichant le prix de l‚Äôachat.\nLa cartographie r√©active sera pr√©sent√©e dans les chapitres\nconsacr√©s √† la visualisation de donn√©es.\nSupposons que le DataFrame des ventes s‚Äôappelle ventes. Il faut d‚Äôabord le\nconvertir\nen objet geopandas.\nAvant de faire une carte, on va convertir\nles limites de la commune de Plogoff en geoJSON pour faciliter\nsa repr√©sentation avec folium\n(voir la doc geopandas √† ce propos):\nPour repr√©senter graphiquement, on peut utiliser le code suivant (essayez de\nle comprendre et pas uniquement de l‚Äôex√©cuter).\n\n# Afficher la carte\nm"
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#g√©ocoder-des-donn√©es-gr√¢ce-aux-api-officielles",
    "href": "content/manipulation/04c_API_TP.html#g√©ocoder-des-donn√©es-gr√¢ce-aux-api-officielles",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "G√©ocoder des donn√©es gr√¢ce aux API officielles",
    "text": "G√©ocoder des donn√©es gr√¢ce aux API officielles\nPour pouvoir faire cet exercice\n\n!pip install xlrd\n\nJusqu‚Äô√† pr√©sent, nous avons travaill√© sur des donn√©es o√π la dimension\ng√©ographique √©tait d√©j√† pr√©sente ou relativement facile √† int√©grer.\nCe cas id√©al ne se rencontre pas n√©cessairement dans la pratique.\nOn dispose parfois de localisations plus ou moins pr√©cises et plus ou\nmoins bien formatt√©es pour d√©terminer la localisation de certains\nlieux.\nDepuis quelques ann√©es, un service officiel de g√©ocodage a √©t√© mis en place.\nCelui-ci est gratuit et permet de mani√®re efficace de coder des adresses\n√† partir d‚Äôune API. Cette API, connue sous le\nnom de la Base d‚ÄôAdresses Nationale (BAN) a b√©n√©fici√© de la mise en commun de donn√©es de plusieurs\nacteurs (collectivit√©s locales, Poste) et de comp√©tences d‚Äôacteurs\ncomme Etalab. La documentation de celle-ci est disponible √† l‚Äôadresse\nhttps://api.gouv.fr/les-api/base-adresse-nationale.\nPour illustrer la mani√®re de g√©ocoder des donn√©es avec Python, nous\nallons partir de la base\ndes r√©sultats des auto-√©coles √† l‚Äôexamen du permis sur l‚Äôann√©e 2018.\nCes donn√©es n√©cessitent un petit peu de travail pour √™tre propres √† une\nanalyse statistique.\nApr√®s avoir renomm√© les colonnes, nous n‚Äôallons conserver que\nles informations relatives au permis B (permis voiture classique) et\nles auto-√©coles ayant pr√©sent√© au moins 20 personnes √† l‚Äôexamen.\n\nimport pandas as pd\nimport xlrd\nimport geopandas as gpd\n\ndf = pd.read_excel(\"https://www.data.gouv.fr/fr/datasets/r/d4b6b072-8a7d-4e04-a029-8cdbdbaf36a5\", header = [0,1])\n\n# Le Excel a des noms de colonne emboit√©es, \n# on nettoie\nindex_0 = [\"\" if df.columns[i][0].startswith(\"Unnamed\") else df.columns[i][0] for i in range(len(df.columns))]\nindex_1 = [df.columns[i][1] for i in range(len(df.columns))]\nkeep_index = [True if el in ('', \"B\") else False for el in index_0] \ncols = [index_0[i] + \" \" + index_1[i].replace(\"+\", \"_\") for i in range(len(df.columns))]\ndf.columns = cols\ndf = df.loc[:, keep_index]\ndf.columns = df.columns.str.replace(\"(^ |¬∞)\", \"\", regex = True).str.replace(\" \", \"_\")\n\n# On garde le sous-√©chantillon d'int√©r√™t\ndf = df.dropna(subset = ['B_NB'])\ndf = df.loc[~df[\"B_NB\"].astype(str).str.contains(\"(\\%|\\.)\"),:]\ndf['B_NB'] = df['B_NB'].astype(int)\ndf['B_TR'] = df['B_TR'].str.replace(\",\", \".\").str.replace(\"%\",\"\").astype(float)\ndf = df.loc[df[\"B_NB\"]&gt;20]\n\n/tmp/ipykernel_220/3216706257.py:19: UserWarning:\n\nThis pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n\n\n\nSur cet √©chantillon, le taux de r√©ussite moyen √©tait, en 2018, de 58.02%\nNos informations g√©ographiques prennent la forme suivante :\n\ndf.loc[:,['Adresse','CP','Ville']].head(5)\n\n\n\n\n\n\n\n\nAdresse\nCP\nVille\n\n\n\n\n0\n56 RUE CHARLES ROBIN\n01000\nBOURG EN BRESSE\n\n\n2\n7, avenue Revermont\n01250\nCeyzeriat\n\n\n3\n72 PLACE DE LA MAIRIE\n01000\nSAINT-DENIS LES BOURG\n\n\n4\n6 RUE DU LYCEE\n01000\nBOURG EN BRESSE\n\n\n5\n9 place Edgard Quinet\n01000\nBOURG EN BRESSE\n\n\n\n\n\n\n\nAutrement dit, nous disposons d‚Äôune adresse, d‚Äôun code postal et d‚Äôun nom\nde ville. Ces informations peuvent servir √† faire une recherche\nsur la localisation d‚Äôune auto-√©cole puis, √©ventuellement, de se restreindre\n√† un sous-√©chantillon.\n\nUtiliser l‚ÄôAPI BAN\nLa documentation officielle de l‚ÄôAPI\npropose un certain nombre d‚Äôexemples de mani√®re de g√©olocaliser des donn√©es.\nDans notre situation, deux points d‚Äôentr√©e paraissent int√©ressants:\n\nL‚ÄôAPI /search/ qui repr√©sente un point d‚Äôentr√©e avec des URL de la forme\nhttps://api-adresse.data.gouv.fr/search/?q=\\&lt;adresse\\&gt;&postcode=\\&lt;codepostal\\&gt;&limit=1\nL‚ÄôAPI /search/csv qui prend un CSV en entr√©e et retourne ce m√™me CSV avec\nles observations g√©ocod√©es. La requ√™te prend la forme suivante, en apparence\nmoins simple √† mettre en oeuvre :\ncurl -X POST -F data=@search.csv -F columns=adresse -F columns=postcode https://api-adresse.data.gouv.fr/search/csv/\n\nLa tentation serait forte d‚Äôutiliser la premi√®re m√©thode avec une boucle sur les\nlignes de notre DataFrame pour g√©ocoder l‚Äôensemble de notre jeu de donn√©es.\nCela serait n√©anmoins une mauvaise id√©e car les communications entre notre\nsession Python et les serveurs de l‚ÄôAPI seraient beaucoup trop nombreuses\npour offrir des performances satisfaisantes.\nPour vous en convaincre, vous pouvez ex√©cuter le code suivant sur un petit\n√©chantillon de donn√©es (par exemple 100 comme ici) et remarquer que le temps\nd‚Äôex√©cution est assez important\n\nimport time\n\ndfgeoloc = df.loc[:, ['Adresse','CP','Ville']].apply(lambda s: s.str.lower().str.replace(\",\",\" \"))\ndfgeoloc['url'] = (dfgeoloc['Adresse'] + \"+\" + dfgeoloc['Ville'].str.replace(\"-\",'+')).str.replace(\" \",\"+\")\ndfgeoloc['url'] = 'https://api-adresse.data.gouv.fr/search/?q=' + dfgeoloc['url'] + \"&postcode=\" + df['CP'] + \"&limit=1\"\ndfgeoloc = dfgeoloc.dropna()\n\nstart_time = time.time()\n\ndef get_geoloc(i):\n    print(i)\n    return gpd.GeoDataFrame.from_features(requests.get(dfgeoloc['url'].iloc[i]).json()['features'])\n\nlocal = [get_geoloc(i) for i in range(len(dfgeoloc.head(10)))]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nComme l‚Äôindique la documentation, si on d√©sire industrialiser notre processus\nde g√©ocodage, on va privil√©gier l‚ÄôAPI CSV.\nPour obtenir une requ√™te CURL coh√©rente avec le format d√©sir√© par l‚ÄôAPI\non va √† nouveau utiliser Requests mais cette fois avec des param√®tres\nsuppl√©mentaires:\n\ndata va nous permettre de passer des param√®tres √† CURL (√©quivalents aux -F\nde la requ√™te CURL) :\n\ncolumns: Les colonnes utilis√©es pour localiser une donn√©e. En l‚Äôoccurrence,\non utilise l‚Äôadresse et la ville (car les codes postaux n‚Äô√©tant pas uniques,\nun m√™me nom de voirie peut se trouver dans plusieurs villes partageant le m√™me\ncode postal) ;\npostcode: Le code postal de la ville. Id√©alement nous aurions utilis√©\nle code Insee mais nous ne l‚Äôavons pas dans nos donn√©es ;\nresult_columns: on restreint les donn√©es √©chang√©es avec l‚ÄôAPI aux\ncolonnes qui nous int√©ressent. Cela permet d‚Äôacc√©l√©rer les processus (on\n√©change moins de donn√©es) et de r√©duire l‚Äôimpact carbone de notre activit√©\n(moins de transferts = moins d‚Äô√©nergie d√©pens√©e). En l‚Äôoccurrence, on ne ressort\nque les donn√©es g√©olocalis√©es et un score de confiance en la g√©olocalisation ;\n\nfiles: permet d‚Äôenvoyer un fichier via CURL.\n\nLes donn√©es sont r√©cup√©r√©es avec request.post. Comme il s‚Äôagit d‚Äôune\ncha√Æne de caract√®re, nous pouvons directement la lire avec Pandas en\nutilisant io.StringIO pour √©viter d‚Äô√©crire des donn√©es interm√©diaires.\nLe nombre d‚Äô√©chos semblant √™tre limit√©, il\nest propos√© de proc√©der par morceaux\n(ici, le jeu de donn√©es est d√©coup√© en 5 morceaux).\n\nimport requests\nimport io   \nimport numpy as np\nimport time\n\nparams = {\n    'columns': ['Adresse', 'Ville'],\n    'postcode': 'CP',\n    'result_columns': ['result_score', 'latitude', 'longitude'],\n}\n\ndf[['Adresse','CP','Ville']] = df.loc[:, ['Adresse','CP','Ville']].apply(lambda s: s.str.lower().str.replace(\",\",\" \"))\n\ndef geoloc_chunk(x):\n    dfgeoloc = x.loc[:, ['Adresse','CP','Ville']]\n    dfgeoloc.to_csv(\"datageocodage.csv\", index=False)\n    response = requests.post('https://api-adresse.data.gouv.fr/search/csv/', data=params, files={'data': ('datageocodage.csv', open('datageocodage.csv', 'rb'))})\n    geoloc = pd.read_csv(io.StringIO(response.text), dtype = {'CP': 'str'})\n    return geoloc\n    \nstart_time = time.time()\ngeodata = [geoloc_chunk(dd) for dd in np.array_split(df, 10)]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nCette m√©thode est beaucoup plus rapide et permet ainsi, une fois retourn√© √† nos\ndonn√©es initiales, d‚Äôavoir un jeu de donn√©es g√©olocalis√©.\n\n# Retour aux donn√©es initiales\ngeodata = pd.concat(geodata, ignore_index = True)\ndf_xy = df.merge(geodata, on = ['Adresse','CP','Ville'])\ndf_xy = df_xy.dropna(subset = ['latitude','longitude'])\n\n# Mise en forme pour le tooltip\ndf_xy['text'] = (\n    df_xy['Raison_Sociale'] + '&lt;br&gt;' +\n    df_xy['Adresse'] + '&lt;br&gt;' +\n    df_xy['Ville'] + '&lt;br&gt;Nombre de candidats:' + df_xy['B_NB'].astype(str)\n)\ndf_xy.filter(\n    ['Raison_Sociale','Adresse','CP','Ville','latitude','longitude'],\n    axis = \"columns\"\n).sample(10)\n\n\n\n\n\n\n\n\nRaison_Sociale\nAdresse\nCP\nVille\nlatitude\nlongitude\n\n\n\n\n2259\nLUISANT MAIRIE\n10 rue de la r√©publique\n28600\nluisant\n48.427830\n1.473003\n\n\n7427\nFRESNOISE\nzone commerciale super u rue abb√© leli√®vre\n72130\nfresnay sur sarthe\n48.285915\n0.022954\n\n\n10047\nZZ-SCEAUX AUTO-ECOLE\n53 rue fontenay\n92330\nsceaux\n48.783695\n2.293347\n\n\n2757\nCONDOMOISE\n33 bd de la liberation\n32100\ncondom\n43.957580\n0.375704\n\n\n907\nAUTO ECOLE PLANET CONDUITE\n173 avenue de la rose\n13013\nmarseille\n43.328926\n5.426850\n\n\n7481\nCRENEAU -LE-\n51 place du forum\n73000\nchambery le haut\n45.593017\n5.919606\n\n\n8933\nTRAJECTOIRE\n49 av de la republique\n83210\nla farlede\n43.165488\n6.042610\n\n\n5758\nAUTO ECOLE BRUNO GODBILLE\n25 ville basse\n59550\nlandrecies\n50.122185\n3.694102\n\n\n4234\nDEGREZ / MACHECOUL CONDUITE\n20 rue de pornic\n44270\nmachecoul\n46.998920\n-1.828172\n\n\n9619\nRIVE DROITE\n19 quai gal leclerc\n89300\njoigny\n47.982360\n3.392759\n\n\n\n\n\n\n\nIl ne reste plus qu‚Äô√† utiliser Geopandas\net nous serons en mesure de faire une carte des localisations des auto-√©coles :\n\n# Transforme en geopandas pour les cartes\nimport geopandas as gpd\ndfgeo = gpd.GeoDataFrame(\n    df_xy,\n    geometry = gpd.points_from_xy(df_xy.longitude, df_xy.latitude)\n)\n\nNous allons repr√©senter les stations dans l‚ÄôEssonne avec un zoom initialement\nsur les villes de Massy et Palaiseau. Le code est le suivant:\n\nimport folium\n\n# Repr√©senter toutes les auto√©coles de l'Essonne\ndf_91 = df_xy.loc[df_xy[\"Dept\"] == \"091\"]\n\n# Centrer la vue initiale sur Massy-Palaiseau\ndf_pal = df_xy.loc[df_xy['Ville'].isin([\"massy\", \"palaiseau\"])]\ncenter = df_pal[['latitude', 'longitude']].mean().values.tolist()\nsw = df_pal[['latitude', 'longitude']].min().values.tolist()\nne = df_pal[['latitude', 'longitude']].max().values.tolist()\n\nm = folium.Map(location = center, tiles='Stamen Toner')\n\n# I can add marker one by one on the map\nfor i in range(0,len(df_91)):\n    folium.Marker([df_91.iloc[i]['latitude'], df_91.iloc[i]['longitude']],\n                  popup=df_91.iloc[i]['text'],\n                  icon=folium.Icon(icon='car', prefix='fa')).add_to(m)\n\nm.fit_bounds([sw, ne])\n\nCe qui permet d‚Äôobtenir la carte:\n\n# Afficher la carte\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nVous pouvez aller plus loin avec l‚Äôexercice suivant.\n\n\n Exercice 2 : Quelles sont les auto-√©coles les plus proches de chez moi ?\nOn va supposer que vous cherchez, dans un rayon donn√© autour d‚Äôun centre ville,\nles auto-√©coles disponibles.\n\n\nFonction n√©cessaire pour cet exercice\n\nCet exercice n√©cessite une fonction pour cr√©er un cercle\nautour d‚Äôun point\n(source ici).\nLa voici :\nfrom functools import partial\nimport pyproj\nfrom shapely.ops import transform\nfrom shapely.geometry import Point\n\nproj_wgs84 = pyproj.Proj('+proj=longlat +datum=WGS84')\n\n\ndef geodesic_point_buffer(lat, lon, km):\n    # Azimuthal equidistant projection\n    aeqd_proj = '+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0'\n    project = partial(\n        pyproj.transform,\n        pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)),\n        proj_wgs84)\n    buf = Point(0, 0).buffer(km * 1000)  # distance in metres\n    return transform(project, buf).exterior.coords[:]\n\n\nPour commencer, utiliser l‚ÄôAPI Geo\npour la ville de Palaiseau.\nAppliquer la fonction geodesic_point_buffer au centre ville de Palaiseau\nNe conserver que les auto-√©coles dans ce cercle et les ordonner\n\nSi vous avez la r√©ponse √† la question 3, n‚Äôh√©sitez pas √† la soumettre sur Github afin que je compl√®te la correction üòâ !\n\n\n\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed\n\n\n\n\n/opt/mamba/lib/python3.9/site-packages/shapely/ops.py:276: FutureWarning:\n\nThis function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n\n\n\nPour se convaincre, de notre cercle constitu√© lors de\nla question 2, on peut repr√©senter une carte.\nOn a bien un cercle centr√© autour de Palaiseau:\n\n\n&lt;Axes: &gt;"
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#exercices-suppl√©mentaires",
    "href": "content/manipulation/04c_API_TP.html#exercices-suppl√©mentaires",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Exercices suppl√©mentaires",
    "text": "Exercices suppl√©mentaires\n\nD√©couvrir l‚ÄôAPI d‚ÄôOpenFoodFacts\nPour vous aidez, vous pouvez regarder une exemple de structure du JSON ici :\nhttps://world.openfoodfacts.org/api/v0/product/3274080005003.json en particulier la cat√©gorie nutriments.\n\n\n Exercice 3 : Retrouver des produits dans l'openfood facts üçï\nVoici une liste de code-barres:\n3274080005003,  5449000000996, 8002270014901, 3228857000906, 3017620421006, 8712100325953\nUtiliser l‚ÄôAPI d‚Äôopenfoodfacts\n(l‚ÄôAPI, pas depuis le CSV !)\npour retrouver les produits correspondants\net leurs caract√©ristiques nutritionnelles.\nLe panier para√Æt-il √©quilibr√© ? üç´\nR√©cup√©rer l‚ÄôURL d‚Äôune des images et l‚Äôafficher dans votre navigateur.\n\n\nVoici par exemple la photo du produit ayant le code-barre 5449000000996. Vous le reconnaissez ?"
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#footnotes",
    "href": "content/manipulation/04c_API_TP.html#footnotes",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa documentation est √©galement disponible ici‚Ü©Ô∏é\nLe JSON est un format tr√®s appr√©ci√© dans le domaine du big data\ncar il permet d‚Äôempiler des donn√©es\nqui ne sont pas compl√®tes. Il\ns‚Äôagit d‚Äôun des formats privil√©gi√©s du paradigme No-SQL pour lequel\ncet excellent cours propose plus de d√©tails.‚Ü©Ô∏é\nSuivant les API, nous avons soit besoin de rien de plus si nous parvenons directement √† obtenir un json, soit devoir utiliser un parser comme BeautifulSoup dans le cas contraire. Ici, le JSON peut √™tre format√© relativement ais√©ment.‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Th√®mes en vrac",
    "section": "",
    "text": "Python pour la data science \n\n\nLino Galiana\n\nStar this website on Github\n\nCe site web rend public le contenu du cours de deuxi√®me ann√©e (Master 1) de l‚ÄôENSAE:\nPython pour la data science\n\nTout est pr√©sent sur ce site web ! Des Notebooks Jupyter peuvent √™tre r√©cup√©r√©s pour s‚Äôexercer. L‚Äôensemble des codes sources est stock√© sur Github\n\n\n\n\n\n\n\n\n\n\n\n\n\nPour d√©couvrir Python  de mani√®re th√©matique\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR√©cup√©rer des donn√©es avec des API depuis Python\n\n\n\nExercice\n\n\nManipulation\n\n\n\nLes API (Application Programming Interface) sont un mode d‚Äôacc√®s aux\ndonn√©es en expansion. Gr√¢ce aux API, l‚Äôautomatisation de scripts\nest facilit√©e puisqu‚Äôil n‚Äôest‚Ä¶\n\n\n\nLino Galiana\n\n\nJul 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\n\n\n\n Back to topCitationBibTeX citation:@book{galiana2023,\n  author = {Galiana, Lino},\n  title = {Python Pour La Data Science},\n  date = {2023},\n  url = {https://pythonds.linogaliana.fr/},\n  doi = {10.5281/zenodo.8229676},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGaliana, Lino. 2023. Python Pour La Data Science. https://doi.org/10.5281/zenodo.8229676."
  }
]